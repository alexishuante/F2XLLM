Code Block 1:
void gemm_parallel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int blockSize = 256;
  int numBlocks = (m * n + blockSize - 1) / blockSize;

  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);

  cudaDeviceSynchronize();
}

__global__ void gemm_parallel_kernel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;

  if (i < m && j < n) {
    float temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 2:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int idy = blockIdx.y * blockDim.y + threadIdx.y;
    if (idx < m && idy < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[idx * lda + l] * b[l * ldb + idy];
        }
        c[idx * ldc + idy] = alpha * temp + beta * c[idx * ldc + idy];
    }
}

Code Block 3:
__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  
  if (i < m && j < n) {
    double temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[IDX2C(i, l, lda)] * b[IDX2C(l, j, ldb)];
    }
    c[IDX2C(i, j, ldc)] = alpha * temp + beta * c[IDX2C(i, j, ldc)];
  }
}

Code Block 4:
void gemm_parallel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int i, j, l;
  float temp;
  float *d_a, *d_b, *d_c;

  // Allocate memory on the GPU
  cudaMalloc((void **)&d_a, lda * k * sizeof(float));
  cudaMalloc((void **)&d_b, ldb * n * sizeof(float));
  cudaMalloc((void **)&d_c, ldc * n * sizeof(float));

  // Copy data from host to device
  cudaMemcpy(d_a, a, lda * k * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, b, ldb * n * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_c, c, ldc * n * sizeof(float), cudaMemcpyHostToDevice);

  // Launch kernel
  gemm_parallel_kernel<<<(m*n)/256+1, 256>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

  // Copy result from device to host
  cudaMemcpy(c, d_c, ldc * n * sizeof(float), cudaMemcpyDeviceToHost);

  // Free memory on the GPU
  cudaFree(d_a);
  cudaFree(d_b);
  cudaFree(d_c);
}

__global__ void gemm_parallel_kernel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  int l;
  float temp;

  if (i < m && j < n) {
    temp = 0.0;
    for (l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 5:
void gemm_parallel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

__global__ void gemm_parallel_kernel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  if (i < m && j < n) {
    float temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 6:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  double *a_d, *b_d, *c_d;

  // Allocate memory on the GPU
  cudaMalloc((void **)&a_d, lda * k * sizeof(double));
  cudaMalloc((void **)&b_d, ldb * n * sizeof(double));
  cudaMalloc((void **)&c_d, ldc * n * sizeof(double));

  // Copy data from host to device
  cudaMemcpy(a_d, a, lda * k * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(b_d, b, ldb * n * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(c_d, c, ldc * n * sizeof(double), cudaMemcpyHostToDevice);

  // Launch the kernel
  gemm_parallel_kernel<<<(m*n + 255) / 256, 256>>>(m, n, k, alpha, a_d, lda, b_d, ldb, beta, c_d, ldc);

  // Copy result from device to host
  cudaMemcpy(c, c_d, ldc * n * sizeof(double), cudaMemcpyDeviceToHost);

  // Free memory on the GPU
  cudaFree(a_d);
  cudaFree(b_d);
  cudaFree(c_d);
}

__global__ void gemm_parallel_kernel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  double temp = 0.0;

  if (i < m && j < n) {
    for (int l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 7:
void gemm_parallel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int i, j, l;
  float temp;
  float *d_a, *d_b, *d_c;

  // Allocate memory on the device
  cudaMalloc((void **)&d_a, lda * k * sizeof(float));
  cudaMalloc((void **)&d_b, ldb * n * sizeof(float));
  cudaMalloc((void **)&d_c, ldc * n * sizeof(float));

  // Copy data from host to device
  cudaMemcpy(d_a, a, lda * k * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, b, ldb * n * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_c, c, ldc * n * sizeof(float), cudaMemcpyHostToDevice);

  // Launch kernel
  dim3 blockSize(16, 16);
  dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);
  gemm_kernel<<<gridSize, blockSize>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

  // Copy result from device to host
  cudaMemcpy(c, d_c, ldc * n * sizeof(float), cudaMemcpyDeviceToHost);

  // Free device memory
  cudaFree(d_a);
  cudaFree(d_b);
  cudaFree(d_c);
}

__global__ void gemm_kernel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;

  if (i < m && j < n) {
    float temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 8:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

__global__ void gemm_parallel_kernel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  if (i < m && j < n) {
    double temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 9:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

__global__ void gemm_parallel_kernel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  if (i < m && j < n) {
    double temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[i * lda + l] * b[l * ldb + j];
    }
    c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
  }
}

Code Block 10:
void gemm_parallel(int m, int n, int k, float alpha, float *a, int lda, float *b, int ldb, float beta, float *c, int ldc) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  int idy = blockIdx.y * blockDim.y + threadIdx.y;
  if (idx < m && idy < n) {
    float temp = 0.0;
    for (int l = 0; l < k; l++) {
      temp += a[idx * lda + l] * b[l * ldb + idy];
    }
    c[idx * ldc + idy] = alpha * temp + beta * c[idx * ldc + idy];
  }
}

