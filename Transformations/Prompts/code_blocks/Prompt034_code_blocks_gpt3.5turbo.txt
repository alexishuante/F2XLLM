Code Block 1:
__global__ void gemv_parallel(int n, float* A, float* x, float* y){
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if(i < n){
        float sum = 0.0;
        for(int j = 0; j < n; j++){
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 2:
__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 3:
vectors
    for (int i = 0; i < n * n; i++) {
        A[i] = i + 1;
    }

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 4:
values
    for (int i = 0; i < n; i++) {
        x[i] = rand() % 10;
        for (int j = 0; j < n; j++) {
            A[i * n + j] = rand() % 10;
        }
    }

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 5:
values
    for (int i = 0; i < n * n; i++) {
        A[i] = rand() % 10;
    }

__global__ void gemv_parallel(int n, float* A, float* x, float* y) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    float sum = 0.0;

    if (tid < n) {
        for (int j = 0; j < n; j++) {
            sum += A[tid * n + j] * x[j];
        }
        y[tid] = sum;
    }
}

Code Block 6:
void gemv(int n, float *A, float *x, float *y) {
    float *d_A, *d_x, *d_y;
    cudaMalloc(&d_A, n * n * sizeof(float));
    cudaMalloc(&d_x, n * sizeof(float));
    cudaMalloc(&d_y, n * sizeof(float));

    cudaMemcpy(d_A, A, n * n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    int block_size = 256;
    int num_blocks = (n + block_size - 1) / block_size;

    gemv_parallel<<<num_blocks, block_size>>>(n, d_A, d_x, d_y);

    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_A);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 7:
x
    for (int i = 0; i < n * n; i++) {
        A[i] = i % n + 1;
    }

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 8:
__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    float sum = 0.0;
    if (i < n) {
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 9:
x
    for (int i = 0; i < n*n; i++) {
        A[i] = i;
    }

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = 0; j < n; j++) {
            sum += A[i*n+j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 10:
x
    for (int i = 0; i < n * n; i++) {
        A[i] = (float)(rand() % 10);
    }

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

