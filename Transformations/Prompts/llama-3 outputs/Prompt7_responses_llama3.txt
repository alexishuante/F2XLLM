Output 1:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp do schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] + u[i][j-1][k] +
                                       u[i][j+1][k] + u[i][j][k-1] + u[i][j][k+1] + u[i][j][k]);
          }
        }
      }
#pragma omp end do
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to use pointers for the 3D arrays, and we also need to explicitly copy the values from unew back to u after the loop. Also, the loop bounds are changed to k < n - 1 and i < n - 1 to avoid accessing out-of-bounds indices.


Output 2:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp for schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i - 1][j][k] + u[i + 1][j][k] + u[i][j - 1][k] +
                                       u[i][j + 1][k] + u[i][j][k - 1] + u[i][j][k + 1] + u[i][j][k]);
          }
        }
      }
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, arrays are passed to functions as pointers, so the u and unew parameters are declared as double *** instead of double[:, :, :] as in Fortran. Also, the kind=8 specifier is not needed in C/C++, as double is the default type for floating-point numbers.


Output 3:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double*** u, double*** unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp for schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            (*unew)[i][j][k] = 0.125 * ((*u)[i-1][j][k] + (*u)[i+1][j][k] + (*u)[i][j-1][k] +
              (*u)[i][j+1][k] + (*u)[i][j][k-1] + (*u)[i][j][k+1] + (*u)[i][j][k]);
          }
        }
      }
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            (*u)[i][j][k] = (*unew)[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to use pointers to pointers to pointers (double***) to represent the 3D array, and we need to dereference the pointers using the * operator. Also, the array indices are represented as i, j, and k instead of i, j, and k as in Fortran.


Output 4:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp do schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] + u[i][j-1][k] +
              u[i][j+1][k] + u[i][j][k-1] + u[i][j][k+1] + u[i][j][k]);
          }
        }
      }
#pragma omp end do
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to use pointers for the 3D arrays, and we also need to explicitly allocate and deallocate memory for the arrays. Also, the loop indices are declared inside the parallel region to make them private to each thread.
Also, the kind=8 in Fortran is equivalent to double in C/C++.


Output 5:
Here is the equivalent C/C++ OpenMP code for the Fortran OpenMP code that implements a Jacobi operation:
#include <iostream>

void jacobi_parallel(double*** u, double*** unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp do schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            (*unew)[i][j][k] = 0.125 * ((*u)[i-1][j][k] + (*u)[i+1][j][k] + (*u)[i][j-1][k] +
              (*u)[i][j+1][k] + (*u)[i][j][k-1] + (*u)[i][j][k+1] + (*u)[i][j][k]);
          }
        }
      }
#pragma omp end do
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            (*u)[i][j][k] = (*unew)[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to pass the 3D array as a pointer to a pointer to a pointer (double***) and access the elements using the dereference operator (*). Also, the schedule(static) clause is used to specify the scheduling of the loop iterations among the threads, and the barrier directive is used to ensure that all threads have finished the computation before updating the u array.


Output 6:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp for schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i - 1][j][k] + u[i + 1][j][k] + u[i][j - 1][k] +
              u[i][j + 1][k] + u[i][j][k - 1] + u[i][j][k + 1] + u[i][j][k]);
          }
        }
      }
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to use pointers for the 3D arrays, and we also need to explicitly allocate and deallocate memory for the arrays. Also, the indexing is 0-based in C/C++, unlike Fortran which is 1-based.


Output 7:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp do schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] + u[i][j-1][k] +
              u[i][j+1][k] + u[i][j][k-1] + u[i][j][k+1] + u[i][j][k]);
          }
        }
      }
#pragma omp end do
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, arrays are passed to functions as pointers, so the u and unew arguments are declared as double *** (pointers to pointers to pointers). Also, the kind=8 specifier in the Fortran code is equivalent to using double in C/C++.


Output 8:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp for schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] + u[i][j-1][k] +
              u[i][j+1][k] + u[i][j][k-1] + u[i][j][k+1] + u[i][j][k]);
          }
        }
      }
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to use pointers for the 3D arrays, and we also need to explicitly allocate and deallocate memory for the arrays. Also, the private clause in the parallel directive is not necessary in this case, as the loop indices are automatically private in OpenMP.
Also, the schedule(static) clause is not necessary in this case, as it is the default schedule for the for directive.
You can call this function like this:
int main() {
  int n = 100;
  int niter = 10;
  int nthreads = 4;
  double ***u, ***unew;

  // Allocate memory for u and unew
  u = new double**[n];
  unew = new double**[n];
  for (int i = 0; i < n; i++) {
    u[i] = new double*[n];
    unew[i] = new double*[n];
    for (int j = 0; j < n; j++) {
      u[i][j] = new double[n];
      unew[i][j] = new double[n];
    }
  }

  // Initialize u and unew
  for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
      for (int k = 0; k < n; k++) {
        u[i][j][k] = 0.0;
        unew[i][j][k] = 0.0;
      }
    }
  }

  jacobi_parallel(u, unew, n, niter, nthreads);

  // Deallocate memory for u and unew
  for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
      delete[] u[i][j];
      delete[] unew[i][j];
    }
    delete[] u[i];
    delete[] unew[i];
  }
  delete[] u;
  delete[] unew;

  return 0;
}
This code allocates memory for the 3D arrays u and unew, initializes them, calls the jacobi_parallel function, and then deallocates the memory.


Output 9:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;
#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp for schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] + u[i][j-1][k] +
                                       u[i][j+1][k] + u[i][j][k-1] + u[i][j][k+1] + u[i][j][k]);
          }
        }
      }
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, arrays are passed to functions as pointers, so the u and unew arrays are declared as double *** instead of double[n][n][n]. Also, the kind=8 attribute in Fortran is equivalent to double in C/C++.
The OpenMP directives are similar in both languages, with the main difference being the syntax for comments (!$OMP in Fortran vs #pragma omp in C/C++).


Output 10:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenMP code:
#include <iostream>

void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
  int i, j, k, iter;

#pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
  {
    for (iter = 1; iter <= niter; iter++) {
#pragma omp for schedule(static)
      for (k = 2; k < n - 1; k++) {
        for (j = 2; j < n - 1; j++) {
          for (i = 2; i < n - 1; i++) {
            unew[i][j][k] = 0.125 * (u[i - 1][j][k] + u[i + 1][j][k] + u[i][j - 1][k] +
              u[i][j + 1][k] + u[i][j][k - 1] + u[i][j][k + 1] + u[i][j][k]);
          }
        }
      }
#pragma omp barrier
      for (k = 0; k < n; k++) {
        for (j = 0; j < n; j++) {
          for (i = 0; i < n; i++) {
            u[i][j][k] = unew[i][j][k];
          }
        }
      }
    }
  }
}
Note that in C/C++, we need to manually manage the memory for the 3D arrays u and unew, which is not shown in this code snippet. Also, the kind=8 attribute in Fortran is equivalent to double in C/C++.


