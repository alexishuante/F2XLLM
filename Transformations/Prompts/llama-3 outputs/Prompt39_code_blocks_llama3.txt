Code Block 1:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;
  
  spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, val, row, col, x, y);
}

Code Block 2:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int i, j;
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;
  
  // Kernel for SpMV
  __global__ void spmv_kernel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
      float sum = 0.0;
      for (int j = row[idx]; j < row[idx+1]; j++) {
        sum += val[j] * x[col[j]];
      }

Code Block 3:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;
  
  spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, val, row, col, x, y);
}

Code Block 4:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;

  spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, val, row, col, x, y);

  cudaDeviceSynchronize();
}

Code Block 5:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int i, j;
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;

  // Kernel function
  __global__ void spmv_kernel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
      float sum = 0.0;
      for (int j = row[idx]; j < row[idx+1]; j++) {
        sum += val[j] * x[col[j]];
      }

Code Block 6:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int i, j;
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;
  
  // Kernel function for SpMV operation
  __global__ void spmv_kernel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
    int idx = blockIdx.x * blockSize + threadIdx.x;
    if (idx < n) {
      float sum = 0.0;
      for (int j = row[idx]; j < row[idx+1]; j++) {
        sum += val[j] * x[col[j]];
      }

Code Block 7:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;

  spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, val, row, col, x, y);

  cudaDeviceSynchronize();
}

Code Block 8:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;

  spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, val, row, col, x, y);

  cudaDeviceSynchronize();
}

Code Block 9:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int i, j;
  float *y_d;
  float *val_d;
  int *row_d;
  int *col_d;
  float *x_d;

  // Allocate device memory
  cudaMalloc((void **)&y_d, n * sizeof(float));
  cudaMalloc((void **)&val_d, nnz * sizeof(float));
  cudaMalloc((void **)&row_d, (n + 1) * sizeof(int));
  cudaMalloc((void **)&col_d, nnz * sizeof(int));
  cudaMalloc((void **)&x_d, n * sizeof(float));

  // Copy host memory to device
  cudaMemcpy(y_d, y, n * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(val_d, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(row_d, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
  cudaMemcpy(col_d, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
  cudaMemcpy(x_d, x, n * sizeof(float), cudaMemcpyHostToDevice);

  // Launch CUDA kernel
  spmv_kernel<<<(n + 255) / 256, 256>>>(n, nnz, val_d, row_d, col_d, x_d, y_d);

  // Copy device memory back to host
  cudaMemcpy(y, y_d, n * sizeof(float), cudaMemcpyDeviceToHost);

  // Free device memory
  cudaFree(y_d);
  cudaFree(val_d);
  cudaFree(row_d);
  cudaFree(col_d);
  cudaFree(x_d);
}

Code Block 10:
void spmv_kernel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    float sum = 0.0;
    for (int j = row[idx]; j < row[idx+1]; j++) {
      sum += val[j] * x[col[j]];
    }

