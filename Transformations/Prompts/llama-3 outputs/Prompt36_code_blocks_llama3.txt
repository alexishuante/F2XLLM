Code Block 1:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  cudaError_t err;

  // Move data to GPU
  double *a_d, *b_d, *c_d;
  cudaMalloc((void **)&a_d, lda * k * sizeof(double));
  cudaMalloc((void **)&b_d, ldb * n * sizeof(double));
  cudaMalloc((void **)&c_d, ldc * n * sizeof(double));
  cudaMemcpy(a_d, a, lda * k * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(b_d, b, ldb * n * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(c_d, c, ldc * n * sizeof(double), cudaMemcpyHostToDevice);

  // Launch kernel
  dim3 blockSize(16, 16);
  dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);
  gemm_kernel<<<gridSize, blockSize>>>(m, n, k, alpha, a_d, lda, b_d, ldb, beta, c_d, ldc);

  // Move result back to host
  cudaMemcpy(c, c_d, ldc * n * sizeof(double), cudaMemcpyDeviceToHost);

  // Free GPU memory
  cudaFree(a_d);
  cudaFree(b_d);
  cudaFree(c_d);

  // Check for errors
  err = cudaGetLastError();
  if (err != cudaSuccess) {
    printf("Error: %s\n", cudaGetErrorString(err));
  }

Code Block 2:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

Code Block 3:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

Code Block 4:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

Code Block 5:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

Code Block 6:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  cudaError_t err;

  // Allocate memory on the GPU
  double *a_d, *b_d, *c_d;
  err = cudaMalloc((void **)&a_d, lda * k * sizeof(double));
  err = cudaMalloc((void **)&b_d, ldb * n * sizeof(double));
  err = cudaMalloc((void **)&c_d, ldc * n * sizeof(double));

  // Copy data from host to device
  err = cudaMemcpy(a_d, a, lda * k * sizeof(double), cudaMemcpyHostToDevice);
  err = cudaMemcpy(b_d, b, ldb * n * sizeof(double), cudaMemcpyHostToDevice);
  err = cudaMemcpy(c_d, c, ldc * n * sizeof(double), cudaMemcpyHostToDevice);

  // Launch kernel
  dim3 blockSize(16, 16);
  dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);
  gemm_kernel<<<gridSize, blockSize>>>(m, n, k, alpha, a_d, lda, b_d, ldb, beta, c_d, ldc);

  // Copy result from device to host
  err = cudaMemcpy(c, c_d, ldc * n * sizeof(double), cudaMemcpyDeviceToHost);

  // Free memory on the GPU
  cudaFree(a_d);
  cudaFree(b_d);
  cudaFree(c_d);
}

Code Block 7:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

Code Block 8:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

Code Block 9:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 256;
  int numBlocks = (m * n + blockSize - 1) / blockSize;
  
  gemm_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
  
  cudaDeviceSynchronize();
}

Code Block 10:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int blockSize = 16;
  int numBlocks = (m + blockSize - 1) / blockSize;
  gemm_parallel_kernel<<<numBlocks, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}

