Code Block 1:
void jacobi(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;

    int size = n * n * n * sizeof(double);

    cudaMalloc(&d_u, size);
    cudaMalloc(&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 blocks(n/BLOCK_SIZE, n/BLOCK_SIZE, n/BLOCK_SIZE);
    dim3 threads(BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);

    for (int iter = 0; iter < niter; iter++) {
        jacobi_parallel<<<blocks, threads>>>(d_u, d_unew, n);
        cudaDeviceSynchronize();

        cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i >= 1 && i < n-1 && j >= 1 && j < n-1 && k >= 1 && k < n-1) {
        unew[i*n*n + j*n + k] = 0.125 * (u[(i-1)*n*n + j*n + k] + u[(i+1)*n*n + j*n + k] +
                                          u[i*n*n + (j-1)*n + k] + u[i*n*n + (j+1)*n + k] +
                                          u[i*n*n + j*n + k-1] + u[i*n*n + j*n + k+1] +
                                          u[i*n*n + j*n + k]);
    }
}

Code Block 2:
void jacobi_cuda(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);
    
    cudaMalloc((void **)&d_u, size);
    cudaMalloc((void **)&d_unew, size);
    
    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);
    
    dim3 blocks((n-2+BLOCK_SIZE-1)/BLOCK_SIZE, (n-2+BLOCK_SIZE-1)/BLOCK_SIZE, (n-2+BLOCK_SIZE-1)/BLOCK_SIZE);
    dim3 threads(BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);
    
    for (int iter = 0; iter < niter; iter++) {
        jacobi_parallel<<<blocks, threads>>>(d_u, d_unew, n);
        
        double *temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }
    
    cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);
    
    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;
    
    if (i < n-1 && j < n-1 && k < n-1) {
        unew[i + j*n + k*n*n] = 0.125 * (u[(i-1) + j*n + k*n*n] + u[(i+1) + j*n + k*n*n] +
            u[i + (j-1)*n + k*n*n] + u[i + (j+1)*n + k*n*n] + u[i + j*n + (k-1)*n*n] +
            u[i + j*n + (k+1)*n*n] + u[i + j*n + k*n*n]);
    }
}

Code Block 3:
void jacobi_cuda(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);

    cudaMalloc((void **)&d_u, size);
    cudaMalloc((void **)&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(BLOCK_SIZE, BLOCK_SIZE);
    dim3 numBlocks((n-2 + BLOCK_SIZE-1)/BLOCK_SIZE, (n-2 + BLOCK_SIZE-1)/BLOCK_SIZE, n-2);

    for(int iter = 0; iter < niter; iter++) {
        jacobi_parallel<<<numBlocks, threadsPerBlock>>>(d_u, d_unew, n);
        cudaMemcpy(unew, d_unew, size, cudaMemcpyDeviceToHost);
        cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double *u, double *unew, int n) {
    int i = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int j = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int k = blockIdx.z + 1;

    if(i < n - 1 && j < n - 1 && k < n - 1) {
        unew[i + j*n + k*n*n] = 0.125 * (u[(i-1) + j*n + k*n*n] + u[(i+1) + j*n + k*n*n] + u[i + (j-1)*n + k*n*n] +
                                          u[i + (j+1)*n + k*n*n] + u[i + j*n + (k-1)*n*n] + u[i + j*n + (k+1)*n*n] +
                                          u[i + j*n + k*n*n]);
    }
}

Code Block 4:
void jacobi_cuda(double* u, double* unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);

    cudaMalloc(&d_u, size);
    cudaMalloc(&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 block(8, 8, 8);
    dim3 grid((n+block.x-1)/block.x, (n+block.y-1)/block.y, (n+block.z-1)/block.z);

    for (int iter = 0; iter < niter; iter++) {
        jacobi_parallel<<<grid, block>>>(d_u, d_unew, n);
        cudaMemcpy(d_u, d_unew, size, cudaMemcpyDeviceToDevice);
    }

    cudaMemcpy(unew, d_unew, size, cudaMemcpyDeviceToHost);

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double* u, double* unew, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int idy = blockIdx.y * blockDim.y + threadIdx.y;
    int idz = blockIdx.z * blockDim.z + threadIdx.z;

    if (idx > 0 && idx < n-1 && idy > 0 && idy < n-1 && idz > 0 && idz < n-1) {
        int id = idz * n * n + idy * n + idx;
        unew[id] = 0.125 * (u[(idz-1) * n * n + idy * n + idx] + u[(idz+1) * n * n + idy * n + idx]
                            + u[idz * n * n + (idy-1) * n + idx] + u[idz * n * n + (idy+1) * n + idx]
                            + u[idz * n * n + idy * n + (idx-1)] + u[idz * n * n + idy * n + (idx+1)]
                            + u[idz * n * n + idy * n + idx]);
    }
}

Code Block 5:
void jacobi_parallel_c(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    cudaMalloc(&d_u, n * n * n * sizeof(double));
    cudaMalloc(&d_unew, n * n * n * sizeof(double));
    cudaMemcpy(d_u, u, n * n * n * sizeof(double), cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(16, 16, 16);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x, (n + threadsPerBlock.y - 1) / threadsPerBlock.y, (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 1; iter <= niter; iter++) {
        jacobi_parallel<<<numBlocks, threadsPerBlock>>>(d_u, d_unew, n);
        cudaDeviceSynchronize();
        
        cudaMemcpy(unew, d_unew, n * n * n * sizeof(double), cudaMemcpyDeviceToHost);
        cudaMemcpy(u, d_u, n * n * n * sizeof(double), cudaMemcpyDeviceToHost);
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i > 0 && i < n - 1 && j > 0 && j < n - 1 && k > 0 && k < n - 1) {
        int idx = i + j * n + k * n * n;
        unew[idx] = 0.125 * (u[idx - n] + u[idx + n] + u[idx - n*n] + u[idx + n*n] + u[idx - n*n*n] + u[idx + n*n*n] + u[idx]);
    }
}

Code Block 6:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);

    cudaMalloc(&d_u, size);
    cudaMalloc(&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(16, 16, 16);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; iter++) {
        jacobi_kernel<<<numBlocks, threadsPerBlock>>>(d_u, d_unew, n);

        cudaMemcpy(unew, d_unew, size, cudaMemcpyDeviceToHost);

        cudaMemcpy(d_u, d_unew, size, cudaMemcpyDeviceToDevice);
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    int j = threadIdx.y + blockIdx.y * blockDim.y;
    int k = threadIdx.z + blockIdx.z * blockDim.z;

    if (i >= 1 && i < n-1 && j >= 1 && j < n-1 && k >= 1 && k < n-1) {
        unew[i + j*n + k*n*n] = 0.125 * (u[(i-1) + j*n + k*n*n] + u[(i+1) + j*n + k*n*n] +
                                          u[i + (j-1)*n + k*n*n] + u[i + (j+1)*n + k*n*n] +
                                          u[i + j*n + (k-1)*n*n] + u[i + j*n + (k+1)*n*n] +
                                          u[i + j*n + k*n*n]);
    }
}

Code Block 7:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    int size = n * n * n * sizeof(double);
    double *d_u, *d_unew;
    cudaMalloc((void**)&d_u, size);
    cudaMalloc((void**)&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 blockDim(BLOCK_SIZE_X, BLOCK_SIZE_Y, BLOCK_SIZE_Z);
    dim3 gridDim((n + BLOCK_SIZE_X - 1) / BLOCK_SIZE_X, (n + BLOCK_SIZE_Y - 1) / BLOCK_SIZE_Y, (n + BLOCK_SIZE_Z - 1) / BLOCK_SIZE_Z);

    for (int iter = 1; iter <= niter; iter++) {
        jacobi_kernel<<<gridDim, blockDim>>>(d_u, d_unew, n);
        cudaDeviceSynchronize();

        cudaMemcpy(unew, d_unew, size, cudaMemcpyDeviceToHost);

        double *temp = u;
        u = unew;
        unew = temp;
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i >= 1 && i < n - 1 && j >= 1 && j < n - 1 && k >= 1 && k < n - 1) {
        int idx = i + j * n + k * n * n;
        unew[idx] = 0.125 * (u[idx-1] + u[idx+1] + u[idx-n] + u[idx+n] + u[idx-n*n] + u[idx+n*n] + u[idx]);
    }
}

Code Block 8:
void jacobi_operation(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);

    cudaMalloc(&d_u, size);
    cudaMalloc(&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 blocks(n/8, n/8, n/8);
    dim3 threads(8, 8, 8);

    for (int iter = 0; iter < niter; iter++) {
        jacobi_parallel<<<blocks, threads>>>(d_u, d_unew, n);
        cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i > 0 && i < n-1 && j > 0 && j < n-1 && k > 0 && k < n-1) {
        int idx = (k * n * n) + (j * n) + i;
        unew[idx] = 0.125 * (u[(k * n * n) + ((j-1) * n) + i] +
                             u[(k * n * n) + ((j+1) * n) + i] +
                             u[(k * n * n) + (j * n) + (i-1)] +
                             u[(k * n * n) + (j * n) + (i+1)] +
                             u[((k-1) * n * n) + (j * n) + i] +
                             u[((k+1) * n * n) + (j * n) + i] + u[idx]);
    }
}

Code Block 9:
void jacobi_operation(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);
    
    cudaMalloc(&d_u, size);
    cudaMalloc(&d_unew, size);
    
    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);
    
    dim3 blockDim(8, 8, 8);
    dim3 gridDim((n + blockDim.x - 1) / blockDim.x, (n + blockDim.y - 1) / blockDim.y, (n + blockDim.z - 1) / blockDim.z);
    
    for (int iter = 0; iter < niter; iter++) {
        jacobi_parallel<<<gridDim, blockDim>>>(d_u, d_unew, n);
        
        cudaMemcpy(unew, d_unew, size, cudaMemcpyDeviceToHost);
        cudaMemcpy(u, unew, size, cudaMemcpyHostToDevice);
    }
    
    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_parallel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i > 0 && i < n - 1 && j > 0 && j < n - 1 && k > 0 && k < n - 1) {
        unew[i + n*j + n*n*k] = 0.125 * (u[(i-1) + n*j + n*n*k] + u[(i+1) + n*j + n*n*k] + u[i + n*(j-1) + n*n*k] +
                                          u[i + n*(j+1) + n*n*k] + u[i + n*j + n*n*(k-1)] + u[i + n*j + n*n*(k+1)] +
                                          u[i + n*j + n*n*k]);
    }
}

Code Block 10:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    int size = n * n * n * sizeof(double);

    cudaMalloc((void**)&d_u, size);
    cudaMalloc((void**)&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; iter++) {
        jacobi_kernel<<<numBlocks, threadsPerBlock>>>(d_u, d_unew, n);
        cudaDeviceSynchronize();

        cudaMemcpy(unew, d_unew, size, cudaMemcpyDeviceToHost);

        cudaMemcpy(d_u, d_unew, size, cudaMemcpyDeviceToDevice);
    }

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i > 0 && i < n - 1 && j > 0 && j < n - 1 && k > 0 && k < n - 1) {
        int index = i + j * n + k * n * n;
        unew[index] = 0.125 * (u[index - 1] + u[index + 1] + u[index - n] +
                               u[index + n] + u[index - n * n] + u[index + n * n] + u[index]);
    }
}

