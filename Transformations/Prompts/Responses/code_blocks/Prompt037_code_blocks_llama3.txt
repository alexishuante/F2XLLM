Code Block 1:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
  int blockSize = BLOCK_SIZE;
  int numBlocks = (n - 2) / blockSize + 1;

  dim3 threadsPerBlock(blockSize, blockSize, blockSize);
  dim3 numBlocksPerGrid(numBlocks, numBlocks, numBlocks);

  for (int iter = 0; iter < niter; iter++) {
    jacobi_kernel<<<numBlocksPerGrid, threadsPerBlock>>>(u, unew, n);
    cudaDeviceSynchronize();
    double *tmp = u;
    u = unew;
    unew = tmp;
  }
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * BLOCK_SIZE + threadIdx.x + 1;
  int j = blockIdx.y * BLOCK_SIZE + threadIdx.y + 1;
  int k = blockIdx.z * BLOCK_SIZE + threadIdx.z + 1;

  if (i < n - 1 && j < n - 1 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125 * (
      u[(i - 1) * n * n + j * n + k] + u[(i + 1) * n * n + j * n + k] +
      u[i * n * n + (j - 1) * n + k] + u[i * n * n + (j + 1) * n + k] +
      u[i * n * n + j * n + (k - 1)] + u[i * n * n + j * n + (k + 1)] +
      u[i * n * n + j * n + k]
    );
  }
}

Code Block 2:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
  int blockSize = BLOCK_SIZE;
  int numBlocks = (n + blockSize - 1) / blockSize;

  double *d_u, *d_unew;

  cudaMalloc((void **)&d_u, n * n * n * sizeof(double));
  cudaMalloc((void **)&d_unew, n * n * n * sizeof(double));

  cudaMemcpy(d_u, u, n * n * n * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(d_unew, unew, n * n * n * sizeof(double), cudaMemcpyHostToDevice);

  for (int iter = 0; iter < niter; iter++) {
    dim3 block(blockSize, blockSize, blockSize);
    dim3 grid(numBlocks, numBlocks, numBlocks);

    jacobi_kernel<<<grid, block>>>(d_u, d_unew, n);

    cudaDeviceSynchronize();

    double *tmp = d_u;
    d_u = d_unew;
    d_unew = tmp;
  }

  cudaMemcpy(u, d_u, n * n * n * sizeof(double), cudaMemcpyDeviceToHost);

  cudaFree(d_u);
  cudaFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * BLOCK_SIZE + threadIdx.x + 1;
  int j = blockIdx.y * BLOCK_SIZE + threadIdx.y + 1;
  int k = blockIdx.z * BLOCK_SIZE + threadIdx.z + 1;

  if (i < n - 1 && j < n - 1 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125 * (
      u[(i - 1) * n * n + j * n + k] + u[(i + 1) * n * n + j * n + k] +
      u[i * n * n + (j - 1) * n + k] + u[i * n * n + (j + 1) * n + k] +
      u[i * n * n + j * n + (k - 1)] + u[i * n * n + j * n + (k + 1)] +
      u[i * n * n + j * n + k]
    );
  }
}

Code Block 3:
void jacobi_parallel(float *u, float *unew, int n, int niter, int nthreads) {
  int blockSize = 16;
  int numBlocks = (n + blockSize - 1) / blockSize;

  dim3 block(blockSize, blockSize, blockSize);
  dim3 grid(numBlocks, numBlocks, numBlocks);

  for (int iter = 0; iter < niter; iter++) {
    jacobi_kernel<<<grid, block>>>(u, unew, n);
    cudaDeviceSynchronize();
    float *tmp = u;
    u = unew;
    unew = tmp;
  }
}

__global__ void jacobi_kernel(float *u, float *unew, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  int k = blockIdx.z * blockDim.z + threadIdx.z;

  if (i >= 2 && i < n - 1 && j >= 2 && j < n - 1 && k >= 2 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125f * (
      u[(i-1) * n * n + j * n + k] + u[(i+1) * n * n + j * n + k] +
      u[i * n * n + (j-1) * n + k] + u[i * n * n + (j+1) * n + k] +
      u[i * n * n + j * n + (k-1)] + u[i * n * n + j * n + (k+1)] +
      u[i * n * n + j * n + k]
    );
  }
}

Code Block 4:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
  int blockSize = BLOCK_SIZE;
  int numBlocks = (n + blockSize - 1) / blockSize;

  dim3 block(blockSize, blockSize, blockSize);
  dim3 grid(numBlocks, numBlocks, numBlocks);

  double *u_d, *unew_d;

  cudaMalloc((void **)&u_d, n * n * n * sizeof(double));
  cudaMalloc((void **)&unew_d, n * n * n * sizeof(double));

  cudaMemcpy(u_d, u, n * n * n * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(unew_d, unew, n * n * n * sizeof(double), cudaMemcpyHostToDevice);

  for (int iter = 0; iter < niter; iter++) {
    jacobi_kernel<<<grid, block>>>(u_d, unew_d, n);
    cudaDeviceSynchronize();
    cudaMemcpy(u_d, unew_d, n * n * n * sizeof(double), cudaMemcpyDeviceToDevice);
  }

  cudaMemcpy(u, u_d, n * n * n * sizeof(double), cudaMemcpyDeviceToHost);

  cudaFree(u_d);
  cudaFree(unew_d);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * BLOCK_SIZE + threadIdx.x + 1;
  int j = blockIdx.y * BLOCK_SIZE + threadIdx.y + 1;
  int k = blockIdx.z * BLOCK_SIZE + threadIdx.z + 1;

  if (i < n-1 && j < n-1 && k < n-1) {
    unew[i*n*n + j*n + k] = 0.125 * (u[(i-1)*n*n + j*n + k] + u[(i+1)*n*n + j*n + k] +
                                     u[i*n*n + (j-1)*n + k] + u[i*n*n + (j+1)*n + k] +
                                     u[i*n*n + j*n + (k-1)] + u[i*n*n + j*n + (k+1)] + u[i*n*n + j*n + k]);
  }
}

Code Block 5:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
  int blockSize = 16;
  int numBlocks = (n + blockSize - 1) / blockSize;

  dim3 block(blockSize, blockSize, blockSize);
  dim3 grid(numBlocks, numBlocks, numBlocks);

  for (int iter = 0; iter < niter; iter++) {
    jacobi_kernel<<<grid, block>>>(u, unew, n);
    cudaDeviceSynchronize();
    double *tmp = u;
    u = unew;
    unew = tmp;
  }
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  int k = blockIdx.z * blockDim.z + threadIdx.z;

  if (i >= 2 && i < n - 1 && j >= 2 && j < n - 1 && k >= 2 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125 * (
      u[(i-1) * n * n + j * n + k] + u[(i+1) * n * n + j * n + k] +
      u[i * n * n + (j-1) * n + k] + u[i * n * n + (j+1) * n + k] +
      u[i * n * n + j * n + (k-1)] + u[i * n * n + j * n + (k+1)] +
      u[i * n * n + j * n + k]);
  }
}

Code Block 6:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
  int blockSize = 16;
  int numBlocks = (n + blockSize - 1) / blockSize;

  dim3 block(blockSize, blockSize, blockSize);
  dim3 grid(numBlocks, numBlocks, numBlocks);

  for (int iter = 0; iter < niter; iter++) {
    jacobi_kernel<<<grid, block>>>(u, unew, n);
    cudaDeviceSynchronize();
    double *tmp = u;
    u = unew;
    unew = tmp;
  }
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  int k = blockIdx.z * blockDim.z + threadIdx.z;

  if (i >= 2 && i < n - 1 && j >= 2 && j < n - 1 && k >= 2 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125 * (u[(i-1) * n * n + j * n + k] +
                                            u[(i+1) * n * n + j * n + k] +
                                            u[i * n * n + (j-1) * n + k] +
                                            u[i * n * n + (j+1) * n + k] +
                                            u[i * n * n + j * n + (k-1)] +
                                            u[i * n * n + j * n + (k+1)] +
                                            u[i * n * n + j * n + k]);
  }
}

Code Block 7:
void jacobi_parallel(float *u, float *unew, int n, int niter, int blockSize, int numBlocks) {
  int idx = blockIdx.x * blockSize + threadIdx.x;
  int idy = blockIdx.y * blockSize + threadIdx.y;
  int idz = blockIdx.z * blockSize + threadIdx.z;

  if (idx >= 2 && idx < n - 1 && idy >= 2 && idy < n - 1 && idz >= 2 && idz < n - 1) {
    for (int iter = 0; iter < niter; iter++) {
      unew[idx + idy * n + idz * n * n] = 0.125f * (
        u[(idx - 1) + idy * n + idz * n * n] +
        u[(idx + 1) + idy * n + idz * n * n] +
        u[idx + (idy - 1) * n + idz * n * n] +
        u[idx + (idy + 1) * n + idz * n * n] +
        u[idx + idy * n + (idz - 1) * n * n] +
        u[idx + idy * n + (idz + 1) * n * n] +
        u[idx + idy * n + idz * n * n]
      );
    }
  }
}

Code Block 8:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
  int blockSize = BLOCK_SIZE;
  int numBlocks = (n + blockSize - 1) / blockSize;

  double *d_u, *d_unew;

  cudaMalloc((void **)&d_u, n * n * n * sizeof(double));
  cudaMalloc((void **)&d_unew, n * n * n * sizeof(double));

  cudaMemcpy(d_u, u, n * n * n * sizeof(double), cudaMemcpyHostToDevice);
  cudaMemcpy(d_unew, unew, n * n * n * sizeof(double), cudaMemcpyHostToDevice);

  for (int iter = 0; iter < niter; iter++) {
    dim3 grid(numBlocks, numBlocks, numBlocks);
    dim3 block(blockSize, blockSize, blockSize);

    jacobi_kernel<<<grid, block>>>(d_u, d_unew, n);

    cudaDeviceSynchronize();

    double *tmp = d_u;
    d_u = d_unew;
    d_unew = tmp;
  }

  cudaMemcpy(u, d_u, n * n * n * sizeof(double), cudaMemcpyDeviceToHost);

  cudaFree(d_u);
  cudaFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * BLOCK_SIZE + threadIdx.x;
  int j = blockIdx.y * BLOCK_SIZE + threadIdx.y;
  int k = blockIdx.z * BLOCK_SIZE + threadIdx.z;

  if (i >= 2 && i < n - 1 && j >= 2 && j < n - 1 && k >= 2 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125 * (
      u[(i - 1) * n * n + j * n + k] +
      u[(i + 1) * n * n + j * n + k] +
      u[i * n * n + (j - 1) * n + k] +
      u[i * n * n + (j + 1) * n + k] +
      u[i * n * n + j * n + (k - 1)] +
      u[i * n * n + j * n + (k + 1)] +
      u[i * n * n + j * n + k]
    );
  }
}

Code Block 9:
void jacobi_parallel(double *u, double *unew, int n, int niter) {
  int size = n * n * n * sizeof(double);
  double *d_u, *d_unew;

  cudaMalloc((void **)&d_u, size);
  cudaMalloc((void **)&d_unew, size);

  cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);
  cudaMemcpy(d_unew, unew, size, cudaMemcpyHostToDevice);

  dim3 blockSize(BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE);
  dim3 gridSize((n + blockSize.x - 1) / blockSize.x,
               (n + blockSize.y - 1) / blockSize.y,
               (n + blockSize.z - 1) / blockSize.z);

  for (int iter = 0; iter < niter; iter++) {
    jacobi_kernel<<<gridSize, blockSize>>>(d_u, d_unew, n);
    cudaDeviceSynchronize();
    double *temp = d_u;
    d_u = d_unew;
    d_unew = temp;
  }

  cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);

  cudaFree(d_u);
  cudaFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  int k = blockIdx.z * blockDim.z + threadIdx.z;

  if (i >= 1 && i < n - 1 && j >= 1 && j < n - 1 && k >= 1 && k < n - 1) {
    unew[i * n * n + j * n + k] = 0.125 * (
      u[(i - 1) * n * n + j * n + k] +
      u[(i + 1) * n * n + j * n + k] +
      u[i * n * n + (j - 1) * n + k] +
      u[i * n * n + (j + 1) * n + k] +
      u[i * n * n + j * n + (k - 1)] +
      u[i * n * n + j * n + (k + 1)] +
      u[i * n * n + j * n + k]);
  }
}

Code Block 10:
void jacobi_parallel_cuda(float *u, float *unew, int n, int niter, int blockSize, int numBlocks) {
  int idx = blockIdx.x * blockSize + threadIdx.x;
  int idy = blockIdx.y * blockSize + threadIdx.y;
  int idz = blockIdx.z * blockSize + threadIdx.z;

  if (idx < n && idy < n && idz < n) {
    for (int iter = 0; iter < niter; iter++) {
      if (idx > 1 && idx < n - 1 && idy > 1 && idy < n - 1 && idz > 1 && idz < n - 1) {
        unew[idx * n * n + idy * n + idz] = 0.125f * (
          u[(idx - 1) * n * n + idy * n + idz] +
          u[(idx + 1) * n * n + idy * n + idz] +
          u[idx * n * n + (idy - 1) * n + idz] +
          u[idx * n * n + (idy + 1) * n + idz] +
          u[idx * n * n + idy * n + (idz - 1)] +
          u[idx * n * n + idy * n + (idz + 1)] +
          u[idx * n * n + idy * n + idz]
        );
      }
      __syncthreads();
      float *tmp = u;
      u = unew;
      unew = tmp;
    }
  }
}

