Code Block 1:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int i, j;
  float sum;

  // Initialize CUDA
  cudaError_t err = cudaSuccess;
  int numBlocks, numThreads;
  numBlocks = (n + 255) / 256;
  numThreads = 256;

  // Allocate device memory
  float *d_A, *d_x, *d_y;
  err = cudaMalloc((void **)&d_A, n * n * sizeof(float));
  err = cudaMalloc((void **)&d_x, n * sizeof(float));
  err = cudaMalloc((void **)&d_y, n * sizeof(float));

  // Copy host memory to device
  err = cudaMemcpy(d_A, A, n * n * sizeof(float), cudaMemcpyHostToDevice);
  err = cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

  // Launch kernel
  gemv_kernel<<<numBlocks, numThreads>>>(n, d_A, d_x, d_y);

  // Copy device memory to host
  err = cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

  // Free device memory
  err = cudaFree(d_A);
  err = cudaFree(d_x);
  err = cudaFree(d_y);
}

__global__ void gemv_kernel(int n, float *A, float *x, float *y) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n) {
    float sum = 0.0;
    for (int j = 0; j < n; j++) {
      sum += A[i * n + j] * x[j];
    }
    y[i] = sum;
  }
}

Code Block 2:
void gemv_parallel(const int n, const float *A, const float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;

  gemv_parallel_kernel<<<numBlocks, blockSize>>>(n, A, x, y);

  CHECK_CUDA_ERROR(cudaDeviceSynchronize());
}

__global__ void gemv_parallel_kernel(const int n, const float *A, const float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;

  if (idx < n) {
    float sum = 0.0f;
    for (int j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

Code Block 3:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int i, j;
  float sum;
  int idx = blockIdx.x * blockDim.x + threadIdx.x;

  if (idx < n) {
    sum = 0.0;
    for (j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

Code Block 4:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    float sum = 0.0;
    for (int j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

Code Block 5:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    float sum = 0.0f;
    for (int j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

Code Block 6:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    float sum = 0.0;
    for (int j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

Code Block 7:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int i, j;
  float sum;

  // CUDA kernel
  __global__ void gemv_kernel(int n, float *A, float *x, float *y) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
      sum = 0.0;
      for (j = 0; j < n; j++) {
        sum += A[idx * n + j] * x[j];
      }
      y[idx] = sum;
    }
  }

  // CUDA kernel launch
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;
  gemv_kernel<<<numBlocks, blockSize>>>(n, A, x, y);
  cudaDeviceSynchronize();
}

__global__ void gemv_kernel(int n, float *A, float *x, float *y) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
      sum = 0.0;
      for (j = 0; j < n; j++) {
        sum += A[idx * n + j] * x[j];
      }
      y[idx] = sum;
    }
  }

Code Block 8:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    float sum = 0.0f;
    for (int j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

Code Block 9:
void gemv_parallel(int n, float *A, float *x, float *y) {
  int i, j;
  float sum;

  // Initialize CUDA variables
  float *d_A, *d_x, *d_y;
  cudaMalloc((void **)&d_A, n * n * sizeof(float));
  cudaMalloc((void **)&d_x, n * sizeof(float));
  cudaMalloc((void **)&d_y, n * sizeof(float));

  // Copy data to GPU
  cudaMemcpy(d_A, A, n * n * sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

  // Launch CUDA kernel
  dim3 blockSize(256, 1, 1);
  dim3 gridSize((n + blockSize.x - 1) / blockSize.x, 1, 1);
  gemv_kernel<<<gridSize, blockSize>>>(n, d_A, d_x, d_y);

  // Copy result back to host
  cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

  // Free CUDA memory
  cudaFree(d_A);
  cudaFree(d_x);
  cudaFree(d_y);
}

__global__ void gemv_kernel(int n, float *A, float *x, float *y) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if (i < n) {
    float sum = 0.0;
    for (int j = 0; j < n; j++) {
      sum += A[i * n + j] * x[j];
    }
    y[i] = sum;
  }
}

Code Block 10:
void gemv_cuda(int n, float *A, float *x, float *y) {
  int blockSize = 256;
  int numBlocks = (n + blockSize - 1) / blockSize;

  gemv_kernel<<<numBlocks, blockSize>>>(n, A, x, y);

  cudaDeviceSynchronize();
}

__global__ void gemv_kernel(int n, float *A, float *x, float *y) {
  int idx = blockIdx.x * blockDim.x + threadIdx.x;
  if (idx < n) {
    float sum = 0.0;
    for (int j = 0; j < n; j++) {
      sum += A[idx * n + j] * x[j];
    }
    y[idx] = sum;
  }
}

