Code Block 1:
index
    if (i < n) {
        y[i] = a * x[i] + y[i]; // Perform AXPY operation
    }

__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x; // Calculate global thread index
    if (i < n) {
        y[i] = a * x[i] + y[i]; // Perform AXPY operation
    }
}

Code Block 2:
ID
    if (i < n) { // Ensure we don't go out of bounds
        y[i] = a * x[i] + y[i];
    }

__global__ void saxpyKernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x; // Calculate global thread ID
    if (i < n) { // Ensure we don't go out of bounds
        y[i] = a * x[i] + y[i];
    }
}

Code Block 3:
result
    for (int i = 0; i < n; i++) {
        if (h_y[i] != 4.0f) {
            printf("Error at index %d: %f\n", i, h_y[i]);
            break;
        }
    }

__global__ void saxpy(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 4:
vectors
    for (int i = 0; i < n; i++) {
        h_x[i] = 1.0f; // Example initialization
        h_y[i] = 2.0f; // Example initialization
    }

__global__ void saxpy(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 5:
void saxpy(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate device memory
    cudaMalloc((void **)&d_x, size);
    cudaMalloc((void **)&d_y, size);

    // Copy data from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Define the number of blocks and threads per block
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the saxpy kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Check for any errors in kernel launch (e.g. invalid execution configuration parameters)
    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        fprintf(stderr, "Failed to launch saxpy kernel (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
    }

    // Wait for the device to complete all operations
    err = cudaDeviceSynchronize();
    if (err != cudaSuccess) {
        fprintf(stderr, "Device synchronization failed (error code %s)!\n", cudaGetErrorString(err));
        exit(EXIT_FAILURE);
    }

    // Copy result back to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 6:
void saxpy_cuda(int n, float a, const float *x, float *y) {
    float *d_x, *d_y;
    
    // Allocate device memory
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    
    // Choose a block size for the kernel launch
    int blockSize = 256;
    // Calculate number of blocks needed
    int numBlocks = (n + blockSize - 1) / blockSize;
    
    // Launch the saxpy kernel
    saxpy<<<numBlocks, blockSize>>>(n, a, d_x, d_y);
    
    // Copy the result back to the host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void saxpy(int n, float a, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if(i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 7:
arrays
    for (int i = 0; i < n; i++) {
        h_x[i] = i * 0.5f;
        h_y[i] = i * 0.5f;
    }

__global__ void saxpy(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 8:
void saxpyCuda(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    
    // Allocate device memory
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Define the block size and the number of blocks
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the CUDA kernel
    saxpy<<<numBlocks, blockSize>>>(n, a, d_x, d_y);
    
    // Copy the result back from the device to the host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void saxpy(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 9:
void saxpy(int n, float a, float *x, float *y) {
    float *d_x, *d_y;

    // Allocate device memory
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy vectors from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch kernel with enough blocks to cover the input vector
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result vector from device back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

Code Block 10:
void saxpy(int n, float a, const float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate device memory
    cudaMalloc((void**)&d_x, size);
    cudaMalloc((void**)&d_y, size);

    // Copy input arrays from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Define a reasonable number of threads per block and calculate the number of blocks required
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // Launch the CUDA kernel
    saxpy_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, a, d_x, d_y);

    // Copy the result array from device to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void saxpy_kernel(int n, float a, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

