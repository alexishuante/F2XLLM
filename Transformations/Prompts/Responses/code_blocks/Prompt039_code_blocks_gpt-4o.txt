Code Block 1:
define cudaCheckError() {                                          \
    cudaError_t e=cudaGetLastError();                                \
    if(e!=cudaSuccess) {                                              \
        printf("CUDA error %s:%d: %s\n", __FILE__,__LINE__,           \
                cudaGetErrorString(e));                               \
        exit(EXIT_FAILURE);                                           \
    }                                                                 \
}

__global__ void spmv_kernel(int n, int nnz, float* val, int* row, int* col, float* x, float* y) {
    // Get thread index
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i >= n) return;

    float sum = 0.0f;
    for (int j = row[i]; j < row[i + 1]; j++) {
        sum += val[j] * x[col[j]];
    }
    y[i] = sum;
}

Code Block 2:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void **)&d_val, nnz * sizeof(float));
    cudaMalloc((void **)&d_row, (n+1) * sizeof(int));
    cudaMalloc((void **)&d_col, nnz * sizeof(int));
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n+1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Determine the number of blocks and threads
    int blockSize = 256; 
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the kernel
    spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 3:
index
    
    if (i < n) { // Ensure not out of bounds
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x; // Calculate global thread index
    
    if (i < n) { // Ensure not out of bounds
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 4:
extern "C" void spmv_parallel(int n, int nnz, 
			      const float *val, const int *row, 
			      const int *col, const float *x, 
			      float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Determine block and grid sizes
    int blockSize = 256; // Adjust this based on your needs
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch the CUDA kernel
    spmv_kernel<<<gridSize, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result from device to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void spmv_kernel(const int n, const int nnz, 
			    const float *val, const int *row, 
			    const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i+1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 5:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Device memory pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch kernel with `n` threads
    int blockSize = 256; // Adjust block size as appropriate
    int numBlocks = (n + blockSize - 1) / blockSize;
    spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 6:
void spmv_parallel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Set number of threads and blocks
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch kernel
    spmv_cuda<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void spmv_cuda(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 7:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Device memory allocation
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    CUDA_CALL(cudaMalloc((void**)&d_val, nnz * sizeof(float)));
    CUDA_CALL(cudaMalloc((void**)&d_x, n * sizeof(float)));
    CUDA_CALL(cudaMalloc((void**)&d_y, n * sizeof(float)));
    CUDA_CALL(cudaMalloc((void**)&d_row, (n + 1) * sizeof(int)));
    CUDA_CALL(cudaMalloc((void**)&d_col, nnz * sizeof(int)));

    // Copy data to device
    CUDA_CALL(cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice));
    CUDA_CALL(cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice));
    CUDA_CALL(cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice));
    CUDA_CALL(cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice));

    // Kernel execution parameters
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch kernel
    spmv_kernel<<<gridSize, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    CUDA_CALL(cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost));

    // Free device memory
    CUDA_CALL(cudaFree(d_val));
    CUDA_CALL(cudaFree(d_x));
    CUDA_CALL(cudaFree(d_y));
    CUDA_CALL(cudaFree(d_row));
    CUDA_CALL(cudaFree(d_col));
}

__global__ void spmv_kernel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i+1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 8:
void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
    // Device arrays
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate memory on the device
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Calculate grid and block dimensions
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // Launch the CUDA kernel
    spmv_cuda<<<blocksPerGrid, threadsPerBlock>>>(n, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void spmv_cuda(int n, float *d_val, int *d_row, int *d_col, float *d_x, float *d_y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = d_row[i]; j < d_row[i+1]; j++) {
            sum += d_val[j] * d_x[d_col[j]];
        }
        d_y[i] = sum;
    }
}

Code Block 9:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc(&d_val, nnz * sizeof(float));
    cudaMalloc(&d_x, n * sizeof(float));
    cudaMalloc(&d_y, n * sizeof(float));
    cudaMalloc(&d_row, (n + 1) * sizeof(int));
    cudaMalloc(&d_col, nnz * sizeof(int));

    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);

    // Define the number of threads per block and number of blocks
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // Launch the CUDA kernel
    spmv_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result from device to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_x);
    cudaFree(d_y);
    cudaFree(d_row);
    cudaFree(d_col);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 10:
void spmv_parallel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    // Allocate device memory
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));

    // Copy data to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);

    // Define block size and grid size
    int blockSize = 256;               // Number of threads per block
    int numBlocks = (n + blockSize - 1) / blockSize; // Number of blocks needed

    // Launch the kernel on the GPU
    spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_x);
    cudaFree(d_y);
    cudaFree(d_row);
    cudaFree(d_col);
}

__global__ void spmv_kernel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    // Each thread works on one row of the matrix
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

