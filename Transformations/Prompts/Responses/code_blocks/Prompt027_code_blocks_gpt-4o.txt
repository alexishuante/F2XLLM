Code Block 1:
extern "C" void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate memory on the device
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy the initial data to the device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    // Configure the block and grid sizes
    dim3 dimBlock(16, 16, 1); // Assuming maximum of 256 threads per block in 3D
    dim3 dimGrid((n + dimBlock.x - 3) / dimBlock.x, (n + dimBlock.y - 3) / dimBlock.y, (n + dimBlock.z - 3) / dimBlock.z);

    for (int iter = 0; iter < niter; ++iter) {
        // Launch the kernel
        hipLaunchKernelGGL(jacobi_kernel, dimGrid, dimBlock, 0, 0, d_u, d_unew, n);

        // Swap pointers
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy the final result back to the host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    // Calculate the thread's absolute position in the 3D grid
    int k = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int i = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        int idx = IDX(i, j, k, n);
        unew[idx] = 0.125 * (u[IDX(i-1, j, k, n)] + u[IDX(i+1, j, k, n)] + 
                             u[IDX(i, j-1, k, n)] + u[IDX(i, j+1, k, n)] + 
                             u[IDX(i, j, k-1, n)] + u[IDX(i, j, k+1, n)] + 
                             u[idx]);
    }
}

Code Block 2:
void jacobi_parallel(double* u, double* unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate memory on the device
    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    // Copy initial data to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; iter++) {
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);

        // Swap pointers
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy the result back to the host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    int j = threadIdx.y + blockIdx.y * blockDim.y;
    int k = threadIdx.z + blockIdx.z * blockDim.z;

    if (i >= 1 && i < n-1 && j >= 1 && j < n-1 && k >= 1 && k < n-1) {
        unew[i*n*n + j*n + k] = 0.125 * (
            u[(i-1)*n*n + j*n + k] + u[(i+1)*n*n + j*n + k] +
            u[i*n*n + (j-1)*n + k] + u[i*n*n + (j+1)*n + k] +
            u[i*n*n + j*n + (k-1)] + u[i*n*n + j*n + (k+1)] +
            u[i*n*n + j*n + k]
        );
    }
}

Code Block 3:
extern "C" void jacobi_parallel(double* u, double* unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;

    hipMalloc(&d_u, n * n * n * sizeof(double));
    hipMalloc(&d_unew, n * n * n * sizeof(double));

    hipMemcpy(d_u, u, n * n * n * sizeof(double), hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; ++iter) {
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);
        hipDeviceSynchronize();
        hipMemcpy(d_u, d_unew, n * n * n * sizeof(double), hipMemcpyDeviceToDevice);
    }

    hipMemcpy(u, d_u, n * n * n * sizeof(double), hipMemcpyDeviceToHost);

    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[i*n*n + j*n + k] = 0.125 * (u[(i-1)*n*n + j*n + k] + u[(i+1)*n*n + j*n + k] +
                                         u[i*n*n + (j-1)*n + k] + u[i*n*n + (j+1)*n + k] +
                                         u[i*n*n + j*n + (k-1)] + u[i*n*n + j*n + (k+1)] +
                                         u[i*n*n + j*n + k]);
    }
}

Code Block 4:
void jacobi_parallel(double* u, double* unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate device memory
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy data from host to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; iter++) {
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);
        hipDeviceSynchronize();

        // Swap pointers
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy data from device back to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);
    hipMemcpy(unew, d_unew, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[((k * n + j) * n + i)] = 0.125 * (
            u[(((k * n + j) * n + i) - n*n)] +
            u[(((k * n + j) * n + i) + n*n)] +
            u[(((k * n + j) * n + i) - n)] +
            u[(((k * n + j) * n + i) + n)] +
            u[(((k * n + j) * n + i) - 1)] +
            u[(((k * n + j) * n + i) + 1)] +
            u[(((k * n + j) * n + i))]
        );
    }
}

Code Block 5:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate device memory
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy input arrays to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    // Define grid and block dimensions
    dim3 threadsPerBlock(8, 8, 8);
    dim3 blocksPerGrid(((n-2) + threadsPerBlock.x - 1) / threadsPerBlock.x,
                       ((n-2) + threadsPerBlock.y - 1) / threadsPerBlock.y,
                       ((n-2) + threadsPerBlock.z - 1) / threadsPerBlock.z);

    // Perform iterations
    for (int iter = 0; iter < niter; iter++) {
        jacobi_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_u, d_unew, n);
        hipDeviceSynchronize();

        // Swap pointers for next iteration
        double *temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy result back to host
    hipMemcpy(u, d_unew, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i-1, j, k, n)] + u[IDX(i+1, j, k, n)] + 
                                         u[IDX(i, j-1, k, n)] + u[IDX(i, j+1, k, n)] + 
                                         u[IDX(i, j, k-1, n)] + u[IDX(i, j, k+1, n)] + 
                                         u[IDX(i, j, k, n)]);
    }
}

Code Block 6:
void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u, *d_unew;

    // Allocate device memory
    hipMalloc((void**)&d_u, n * n * n * sizeof(double));
    hipMalloc((void**)&d_unew, n * n * n * sizeof(double));

    // Copy data from host to device
    hipMemcpy(d_u, u, n * n * n * sizeof(double), hipMemcpyHostToDevice);

    // Define the block size and grid size
    dim3 blockSize(8, 8, 8);
    dim3 gridSize((n + blockSize.x - 1) / blockSize.x,
                  (n + blockSize.y - 1) / blockSize.y,
                  (n + blockSize.z - 1) / blockSize.z);

    // Perform iterations
    for (int iter = 0; iter < niter; iter++) {
        // Launch Jacobi kernel
        hipLaunchKernelGGL(jacobi_kernel, gridSize, blockSize, 0, 0, d_u, d_unew, n);

        // Synchronize to ensure kernel execution is done
        hipDeviceSynchronize();

        // Swap pointers
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy result back to host (final result in d_u)
    hipMemcpy(u, d_u, n * n * n * sizeof(double), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__
void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i > 0 && i < n - 1 && j > 0 && j < n - 1 && k > 0 && k < n - 1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i-1, j, k, n)] + u[IDX(i+1, j, k, n)] +
                                         u[IDX(i, j-1, k, n)] + u[IDX(i, j+1, k, n)] +
                                         u[IDX(i, j, k-1, n)] + u[IDX(i, j, k+1, n)] +
                                         u[IDX(i, j, k, n)]);
    }
}

Code Block 7:
void jacobi_parallel(double* u, double* unew, int n, int niter, int threads_per_block_dim) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threads_per_block(threads_per_block_dim, threads_per_block_dim, threads_per_block_dim);
    dim3 number_of_blocks((n + threads_per_block.x - 1) / threads_per_block.x,
                          (n + threads_per_block.y - 1) / threads_per_block.y,
                          (n + threads_per_block.z - 1) / threads_per_block.z);

    for (int iter = 0; iter < niter; iter++) {
        hipLaunchKernelGGL(jacobi_kernel, number_of_blocks, threads_per_block, 0, 0, d_u, d_unew, n);
        hipDeviceSynchronize();

        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i >= 2 && i < n - 1 && j >= 2 && j < n - 1 && k >= 2 && k < n - 1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i-1, j, k, n)] + u[IDX(i+1, j, k, n)] +
                                        u[IDX(i, j-1, k, n)] + u[IDX(i, j+1, k, n)] +
                                        u[IDX(i, j, k-1, n)] + u[IDX(i, j, k+1, n)] +
                                        u[IDX(i, j, k, n)]);
    }
}

Code Block 8:
void jacobi_parallel(double *u, double *unew, int n, int niter, int blockSize) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    hipMalloc((void **)&d_u, size);
    hipMalloc((void **)&d_unew, size);

    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 dimBlock(blockSize, blockSize, blockSize);
    dim3 dimGrid((n + blockSize - 1) / blockSize,
                 (n + blockSize - 1) / blockSize,
                 (n + blockSize - 1) / blockSize);

    jacobi_kernel<<<dimGrid, dimBlock>>>(d_u, d_unew, n, niter);
    hipDeviceSynchronize();

    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);
    hipMemcpy(unew, d_unew, size, hipMemcpyDeviceToHost);

    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n, int niter) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;
    if (i > 0 && i < n-1 && j > 0 && j < n-1 && k > 0 && k < n-1) {
        for (int iter = 0; iter < niter; iter++) {
            unew[i*n*n + j*n + k] = 0.125 * (
                u[(i-1)*n*n + j*n + k] + u[(i+1)*n*n + j*n + k] +
                u[i*n*n + (j-1)*n + k] + u[i*n*n + (j+1)*n + k] +
                u[i*n*n + j*n + (k-1)] + u[i*n*n + j*n + (k+1)] +
                u[i*n*n + j*n + k]
            );
            
            __syncthreads();
            
            // Swapping the pointers for next iteration
            double *temp = u;
            u = unew;
            unew = temp;
            
            __syncthreads();
        }
    }
}

Code Block 9:
void jacobi_parallel(double *u, double *unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate memory on the GPU
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy initial values from host to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    // Perform the Jacobi iterations
    for (int iter = 0; iter < niter; iter++) {
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);

        // Synchronize to ensure all threads complete their work
        hipDeviceSynchronize();

        // Swap pointers
        double *temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy final values from device to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);
    hipMemcpy(unew, d_unew, size, hipMemcpyDeviceToHost);

    // Free GPU memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;

    if (k < n-1 && j < n-1 && i < n-1) {
        int idx = i + j * n + k * n * n;
        unew[idx] = 0.125 * (u[idx - 1] + u[idx + 1] + u[idx - n] +
                    u[idx + n] + u[idx - n * n] + u[idx + n * n] + u[idx]);
    }
}

Code Block 10:
void jacobi_parallel(double* u, double* unew, int n, int niter, int nthreads) {
    double *d_u, *d_unew;

    // Allocate memory on the GPU
    hipMalloc(&d_u, n * n * n * sizeof(double));
    hipMalloc(&d_unew, n * n * n * sizeof(double));

    // Copy the initial data from the host to the device
    hipMemcpy(d_u, u, n * n * n * sizeof(double), hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, n * n * n * sizeof(double), hipMemcpyHostToDevice);

    // Define block and grid dimensions
    dim3 threadsPerBlock(nthreads, nthreads, nthreads);
    dim3 numBlocks((n + nthreads - 1) / nthreads,
                   (n + nthreads - 1) / nthreads,
                   (n + nthreads - 1) / nthreads);

    for (int iter = 0; iter < niter; ++iter) {
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);
        hipDeviceSynchronize();

        // Swap pointers
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy the final data from the device to the host
    hipMemcpy(u, d_u, n * n * n * sizeof(double), hipMemcpyDeviceToHost);

    // Free GPU memory
    hipFree(d_u);
    hipFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i-1, j, k, n)] +
                                         u[IDX(i+1, j, k, n)] +
                                         u[IDX(i, j-1, k, n)] +
                                         u[IDX(i, j+1, k, n)] +
                                         u[IDX(i, j, k-1, n)] +
                                         u[IDX(i, j, k+1, n)] +
                                         u[IDX(i, j, k, n)]);
    }
}

