Code Block 1:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Device pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate memory on the device
    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));

    // Copy data from host to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);
    hipMemset(d_y, 0, n * sizeof(float));

    // Define block and grid sizes
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch kernel
    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 2:
void spmv_parallel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    // Device pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));
    hipMalloc((void**)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));

    // Copy data from host to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_y, y, n * sizeof(float), hipMemcpyHostToDevice);  // Note: y is initialized empty
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);

    // Set up execution configuration
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch the kernel
    hipLaunchKernelGGL(spmv_kernel, dim3(gridSize), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy the result from device to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
    hipFree(d_row);
    hipFree(d_col);
}

__global__ void spmv_kernel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 3:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Device pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc((void **)&d_val, nnz * sizeof(float));
    hipMalloc((void **)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void **)&d_col, nnz * sizeof(int));
    hipMalloc((void **)&d_x, n * sizeof(float));
    hipMalloc((void **)&d_y, n * sizeof(float));

    // Copy data to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);

    // Kernel launch parameters
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch the kernel
    hipLaunchKernelGGL(spmv_kernel, dim3(gridSize), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);
    hipDeviceSynchronize();

    // Copy result back to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 4:
void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

__global__ 
void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 5:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;
    
    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));

    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);

    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    hipLaunchKernelGGL(spmv_parallel_kernel, dim3(blocksPerGrid), dim3(threadsPerBlock), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_parallel_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 6:
void spmv_parallel(int n, int nnz, 
                   const float *val, const int *row, const int *col,
                   const float *x, float *y) {
    // Device pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate memory on the device
    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));

    // Copy data to the device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);
    hipMemset(d_y, 0, n * sizeof(float)); // initialize d_y to 0s

    // Launch the kernel
    int blockSize = 256;  // Adjust block size as needed
    int numBlocks = (n + blockSize - 1) / blockSize;
    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy the result back to the host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free the device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz,
                            const float *val, const int *row, const int *col,
                            const float *x, float *y) {

    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float temp = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            temp += val[j] * x[col[j]];
        }
        y[i] = temp;
    }
}

Code Block 7:
extern "C" void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Device pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc((void **)&d_val, nnz * sizeof(float));
    hipMalloc((void **)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void **)&d_col, nnz * sizeof(int));
    hipMalloc((void **)&d_x, n * sizeof(float));
    hipMalloc((void **)&d_y, n * sizeof(float));

    // Copy data to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);

    // Kernel launch dimensions
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch kernel
    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 8:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));

    // Copy data to device memory
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);

    // Determine grid and block sizes
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch kernel
    hipLaunchKernelGGL(spmv_kernel, dim3(gridSize), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host memory
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 9:
result
    for (int i = 0; i < n; i++) {
        printf("%f ", y[i]);
    }

__global__ void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 10:
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));

    // Copy data to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);

    // Launch kernel
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
    hipFree(d_row);
    hipFree(d_col);
}

__global__ void spmv_kernel(const int n, const int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

