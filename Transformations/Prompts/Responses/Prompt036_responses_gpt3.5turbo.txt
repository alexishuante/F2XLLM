--------------- Output 1 ---------------
```c
#include <stdio.h>
#include <stdlib.h>

__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

int main() {
    int m = 128;
    int n = 128;
    int k = 128;
    double alpha = 1.0;
    double beta = 0.0;
    
    double *a, *b, *c;
    cudaMallocManaged(&a, m*k*sizeof(double));
    cudaMallocManaged(&b, k*n*sizeof(double));
    cudaMallocManaged(&c, m*n*sizeof(double));
    
    // Initialize matrices a and b with random values
    for (int i = 0; i < m*k; i++) {
        a[i] = (double)rand() / RAND_MAX;
    }
    for (int i = 0; i < k*n; i++) {
        b[i] = (double)rand() / RAND_MAX;
    }
    
    dim3 blockSize(16, 16);
    dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);
    
    gemm_parallel<<<gridSize, blockSize>>>(m, n, k, alpha, a, k, b, n, beta, c, n);
    cudaDeviceSynchronize();
    
    cudaFree(a);
    cudaFree(b);
    cudaFree(c);
    
    return 0;
}
```

--------------- Output 2 ---------------
```c
#include <stdlib.h>
#include <stdio.h>

__global__ void gemm_parallel(int m, int n, int k, double alpha, double* a, int lda, double* b, int ldb, double beta, double* c, int ldc) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

int main() {
    int m = 1024;
    int n = 1024;
    int k = 1024;
    double alpha = 1.0;
    double beta = 1.0;

    double *a, *b, *c;
    double *d_a, *d_b, *d_c;

    int lda = k;
    int ldb = n;
    int ldc = n;

    // Allocate memory on host
    a = (double *)malloc(m * k * sizeof(double));
    b = (double *)malloc(k * n * sizeof(double));
    c = (double *)malloc(m * n * sizeof(double));

    // Initialize data on host
    // ...

    // Allocate memory on device
    cudaMalloc((void **)&d_a, m * k * sizeof(double));
    cudaMalloc((void **)&d_b, k * n * sizeof(double));
    cudaMalloc((void **)&d_c, m * n * sizeof(double));

    // Copy data from host to device
    cudaMemcpy(d_a, a, m * k * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, k * n * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_c, c, m * n * sizeof(double), cudaMemcpyHostToDevice);

    // Launch kernel
    dim3 blockSize(16, 16);
    dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);
    gemm_parallel<<<gridSize, blockSize>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

    // Copy result from device to host
    cudaMemcpy(c, d_c, m * n * sizeof(double), cudaMemcpyDeviceToHost);

    // Free memory on device
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    // Free memory on host
    free(a);
    free(b);
    free(c);

    return 0;
}
```

--------------- Output 3 ---------------
```c
#include <stdio.h>

#define BLOCK_SIZE 16

__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i = blockIdx.y * blockDim.y + threadIdx.y;
    int j = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

int main() {
    int m = 128;
    int n = 128;
    int k = 128;
    double alpha = 1.0;
    double beta = 1.0;
    double *a, *b, *c;
    double *d_a, *d_b, *d_c;
    int lda = k;
    int ldb = n;
    int ldc = n;

    // Allocate host memory
    a = (double*)malloc(m * k * sizeof(double));
    b = (double*)malloc(k * n * sizeof(double));
    c = (double*)malloc(m * n * sizeof(double));

    // Initialize host memory
    for (int i = 0; i < m * k; i++) {
        a[i] = i;
    }
    for (int i = 0; i < k * n; i++) {
        b[i] = i;
    }

    // Allocate device memory
    cudaMalloc((void**)&d_a, m * k * sizeof(double));
    cudaMalloc((void**)&d_b, k * n * sizeof(double));
    cudaMalloc((void**)&d_c, m * n * sizeof(double));

    // Copy data to device
    cudaMemcpy(d_a, a, m * k * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, k * n * sizeof(double), cudaMemcpyHostToDevice);

    // Define grid and block dimensions
    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);
    dim3 dimGrid((n + BLOCK_SIZE - 1) / BLOCK_SIZE, (m + BLOCK_SIZE - 1) / BLOCK_SIZE);

    // Call kernel
    gemm_parallel<<<dimGrid, dimBlock>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

    // Copy result back to host
    cudaMemcpy(c, d_c, m * n * sizeof(double), cudaMemcpyDeviceToHost);

    // Print result
    for (int i = 0; i < m; i++) {
        for (int j = 0; j < n; j++) {
            printf("%f ", c[i * ldc + j]);
        }
        printf("\n");
    }

    // Free memory
    free(a);
    free(b);
    free(c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    return 0;
}
```

--------------- Output 4 ---------------
Here is the equivalent function implemented in C with CUDA:

```c
#include <stdio.h>

__global__ void gemm_parallel(int m, int n, int k, double alpha, double* a, int lda, double* b, int ldb, double beta, double* c, int ldc)
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    if(i < m && j < n)
    {
        double temp = 0.0;
        for(int l = 0; l < k; l++)
        {
            temp += a[i*lda + l] * b[l*ldb + j];
        }
        c[i*ldc + j] = alpha * temp + beta * c[i*ldc + j];
    }
}

void gemm(int m, int n, int k, double alpha, double* a, int lda, double* b, int ldb, double beta, double* c, int ldc)
{
    double *d_a, *d_b, *d_c;

    cudaMalloc(&d_a, m*k*sizeof(double));
    cudaMalloc(&d_b, k*n*sizeof(double));
    cudaMalloc(&d_c, m*n*sizeof(double));

    cudaMemcpy(d_a, a, m*k*sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, k*n*sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_c, c, m*n*sizeof(double), cudaMemcpyHostToDevice);

    dim3 blockSize(16, 16);
    dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);

    gemm_parallel<<<gridSize, blockSize>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

    cudaMemcpy(c, d_c, m*n*sizeof(double), cudaMemcpyDeviceToHost);

    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
}

int main()
{
    int m = 3, n = 2, k = 4;
    double alpha = 1.0, beta = 0.0;
    double a[] = {1.0, 2.0, 3.0, 4.0,
                  5.0, 6.0, 7.0, 8.0,
                  9.0, 10.0, 11.0, 12.0};
    double b[] = {1.0, 2.0,
                  3.0, 4.0,
                  5.0, 6.0,
                  7.0, 8.0};
    double c[6];

    gemm(m, n, k, alpha, a, k, b, n, beta, c, n);

    for(int i = 0; i < m; i++)
    {
        for(int j = 0; j < n; j++)
        {
            printf("%.2f\t", c[i*n + j]);
        }
        printf("\n");
    }

    return 0;
}
```

Note: This is a basic example and can be optimized further for better performance.

--------------- Output 5 ---------------
```c
__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i = blockIdx.y * blockDim.y + threadIdx.y;
    int j = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}
```

--------------- Output 6 ---------------
```c
#include <stdio.h>
#include <stdlib.h>

__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    int j = threadIdx.y + blockIdx.y * blockDim.y;

    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

int main() {
    int m = 1024;
    int n = 512;
    int k = 256;
    double alpha = 1.0;
    double beta = 0.0;

    double *a, *b, *c;
    double *d_a, *d_b, *d_c;
    int lda = k;
    int ldb = n;
    int ldc = n;

    // Allocate memory on the host and device
    a = (double*)malloc(sizeof(double) * m * k);
    b = (double*)malloc(sizeof(double) * k * n);
    c = (double*)malloc(sizeof(double) * m * n);
    cudaMalloc(&d_a, sizeof(double) * m * k);
    cudaMalloc(&d_b, sizeof(double) * k * n);
    cudaMalloc(&d_c, sizeof(double) * m * n);

    // Initialize arrays on the host
    for (int i = 0; i < m * k; i++) {
        a[i] = rand() % 10;
    }
    for (int i = 0; i < k * n; i++) {
        b[i] = rand() % 10;
    }

    // Transfer data from host to device
    cudaMemcpy(d_a, a, sizeof(double) * m * k, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, sizeof(double) * k * n, cudaMemcpyHostToDevice);

    // Define grid and block dimensions
    dim3 blockSize(16, 16);
    dim3 gridSize((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);

    // Call kernel function
    gemm_parallel<<<gridSize, blockSize>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

    // Transfer result back to host
    cudaMemcpy(c, d_c, sizeof(double) * m * n, cudaMemcpyDeviceToHost);

    // Free memory
    free(a); free(b); free(c);
    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);

    return 0;
}
```

--------------- Output 7 ---------------
```c
__global__ void gemm_parallel(int m, int n, int k, double alpha, double* a, int lda, double* b, int ldb, double beta, double* c, int ldc) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

void gemm_parallel(int m, int n, int k, double alpha, double* a, int lda, double* b, int ldb, double beta, double* c, int ldc) {
    double *d_a, *d_b, *d_c;

    cudaMalloc(&d_a, m * k * sizeof(double));
    cudaMalloc(&d_b, k * n * sizeof(double));
    cudaMalloc(&d_c, m * n * sizeof(double));

    cudaMemcpy(d_a, a, m * k * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, k * n * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_c, c, m * n * sizeof(double), cudaMemcpyHostToDevice);

    dim3 blockDim(16, 16);
    dim3 gridDim((m + 15) / 16, (n + 15) / 16);

    gemm_parallel<<<gridDim, blockDim>>>(m, n, k, alpha, d_a, lda, d_b, ldb, beta, d_c, ldc);

    cudaMemcpy(c, d_c, m * n * sizeof(double), cudaMemcpyDeviceToHost);

    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
}
```

--------------- Output 8 ---------------
```c
__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int j = blockIdx.x * blockDim.x + threadIdx.x;
    int i = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

void gemm_wrapper(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    dim3 blockSize(16, 16);
    dim3 gridSize((n + blockSize.x - 1) / blockSize.x, (m + blockSize.y - 1) / blockSize.y);
    
    gemm_parallel<<<gridSize, blockSize>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
}
```

--------------- Output 9 ---------------
```c
#include <stdio.h>

__global__ void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; ++l) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

int main() {
    int m = 4, n = 3, k = 2;
    double alpha = 1.0, beta = 0.0;
    double a[m][k] = {{1, 2}, {3, 4}, {5, 6}, {7, 8}};
    double b[k][n] = {{1, 2, 3}, {4, 5, 6}};
    double c[m][n] = {{0}};
    
    double *d_a, *d_b, *d_c;
    cudaMalloc(&d_a, m * k * sizeof(double));
    cudaMalloc(&d_b, k * n * sizeof(double));
    cudaMalloc(&d_c, m * n * sizeof(double));
    
    cudaMemcpy(d_a, a, m * k * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, k * n * sizeof(double), cudaMemcpyHostToDevice);
    
    dim3 blockSize(2, 2);
    dim3 numBlocks((m + blockSize.x - 1) / blockSize.x, (n + blockSize.y - 1) / blockSize.y);
    
    gemm_parallel<<<numBlocks, blockSize>>>(m, n, k, alpha, d_a, k, d_b, n, beta, d_c, n);
    
    cudaMemcpy(c, d_c, m * n * sizeof(double), cudaMemcpyDeviceToHost);
    
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
    
    for (int i = 0; i < m; ++i) {
        for (int j = 0; j < n; ++j) {
            printf("%f ", c[i][j]);
        }
        printf("\n");
    }
    
    return 0;
}
```

--------------- Output 10 ---------------
```c
#include <stdio.h>
#include <cuda.h>

__global__
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    if (i < m && j < n) {
        double temp = 0.0;
        for (int l = 0; l < k; l++) {
            temp += a[i * lda + l] * b[l * ldb + j];
        }
        c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
}

int main() {
    int m = 256, n = 256, k = 256;
    double alpha = 1.0, beta = 1.0;
    double *a, *b, *c;
    int lda = k, ldb = n, ldc = n;

    // Allocate memory on host and device
    size_t size_a = lda * k * sizeof(double);
    size_t size_b = ldb * n * sizeof(double);
    size_t size_c = ldc * n * sizeof(double);
    cudaMallocManaged(&a, size_a);
    cudaMallocManaged(&b, size_b);
    cudaMallocManaged(&c, size_c);

    // Initialize arrays a and b with some values
    for (int i = 0; i < lda * k; i++) {
        a[i] = i;
    }
    for (int i = 0; i < ldb * n; i++) {
        b[i] = i;
    }

    // Set up grid and block dimensions
    dim3 blockDim(16, 16);
    dim3 gridDim((m + blockDim.x - 1) / blockDim.x, (n + blockDim.y - 1) / blockDim.y);

    // Call CUDA kernel
    gemm_parallel<<<gridDim, blockDim>>>(m, n, k, alpha, a, lda, b, ldb, beta, c, ldc);
    cudaDeviceSynchronize();

    // Free memory
    cudaFree(a);
    cudaFree(b);
    cudaFree(c);

    return 0;
}
```

