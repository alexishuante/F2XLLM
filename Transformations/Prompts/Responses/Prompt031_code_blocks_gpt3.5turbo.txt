Code Block 1:
void gemv_parallel(int n, float *A, float *x, float *y) {
    int i, j;
    float sum;

    #pragma omp parallel for private(j, sum)
    for (i = 0; i < n; i++) {
        sum = 0.0;
        for (j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 2:
void gemv_parallel(int n, float *A, float *x, float *y) {
    float *d_A, *d_x, *d_y;
    cudaMalloc(&d_A, n * n * sizeof(float));
    cudaMalloc(&d_x, n * sizeof(float));
    cudaMalloc(&d_y, n * sizeof(float));

    cudaMemcpy(d_A, A, n * n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    int block_size = 256;
    int grid_size = (n + block_size - 1) / block_size;

    gemv_kernel<<<grid_size, block_size>>>(n, d_A, d_x, d_y);

    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_A);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void gemv_kernel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 3:
void gemv_parallel(int n, float *A, float *x, float *y) {
    #pragma omp parallel for
    for (int i = 0; i < n; i++) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 4:
void gemv_parallel(int n, float *A, float *x, float *y) {
    #pragma omp parallel for
    for (int i = 0; i < n; i++) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

__global__
void gemv_parallel_cuda(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 5:
void gemv_parallel_c(int n, float *A, float *x, float *y) {
    float *d_A, *d_x, *d_y;
    cudaMalloc(&d_A, n * n * sizeof(float));
    cudaMalloc(&d_x, n * sizeof(float));
    cudaMalloc(&d_y, n * sizeof(float));
    
    cudaMemcpy(d_A, A, n * n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    
    gemv_parallel<<<(n + 255) / 256, 256>>>(n, d_A, d_x, d_y);
    
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    cudaFree(d_A);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 6:
__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 7:
x
    for (int i = 0; i < N*N; i++) {
        A[i] = i+1;
    }

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 8:
void gemv(int n, float *A, float *x, float *y) {
    for (int i = 0; i < n; i++) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n+j] * x[j];
        }
        y[i] = sum;
    }
}

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n+j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 9:
void gemv_parallel(int n, float A[n][n], float x[n], float y[n]) {
    #pragma omp parallel for
    for (int i = 0; i < n; i++) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i][j] * x[j];
        }
        y[i] = sum;
    }
}

__global__ void gemv_parallel(int n, float* A, float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i * n + j] * x[j];
        }
        y[i] = sum;
    }
}

Code Block 10:
void gemv(int n, float *A, float *x, float *y) {
    float *d_A, *d_x, *d_y;

    cudaMalloc(&d_A, n * n * sizeof(float));
    cudaMalloc(&d_x, n * sizeof(float));
    cudaMalloc(&d_y, n * sizeof(float));

    cudaMemcpy(d_A, A, n * n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    gemv_parallel<<<(n + 255) / 256, 256>>>(n, d_A, d_x, d_y);

    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_A);
    cudaFree(d_x);
    cudaFree(d_y);
}

__global__ void gemv_parallel(int n, float *A, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = 0; j < n; j++) {
            sum += A[i*n + j] * x[j];
        }
        y[i] = sum;
    }
}

