--------------- Code Block 1 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float *x, float *y) {
    // Determine block size and grid size
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Allocate memory on the device
    float *d_x, *d_y;
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the kernel
    saxpy_kernel<<<gridSize, blockSize>>>(n, a, d_x, d_y);

    // Copy the result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 2 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float *x, float *y) {

    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate memory on the GPU
    cudaMalloc((void**)&d_x, size);
    cudaMalloc((void**)&d_y, size);

    // Copy data from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Define block size and number of blocks
    int blockSize = 256; // You can tune this value for best performance
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch SAXPY kernel on the GPU
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result from device to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free allocated memory on the GPU
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 3 ---------------
__global__ void saxpy_kernel(int n, float a, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        y[i] += a * x[i];
    }
}

void saxpy_parallel(int n, float a, const float *x, float *y) {
    int blockSize = 256; // Define the number of threads per block
    int numBlocks = (n + blockSize - 1) / blockSize; // Calculate the number of blocks required

    // Allocate device memory
    float *d_x, *d_y;
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the CUDA kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy the result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 4 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate device memory
    cudaMalloc((void **)&d_x, size);
    cudaMalloc((void **)&d_y, size);
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Define grid and block sizes
    int blockSize = 256;            // Number of threads per block
    int numBlocks = (n + blockSize - 1) / blockSize;  // Number of blocks

    // Launch the CUDA kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Synchronize the device
    cudaDeviceSynchronize();
    
    // Copy result back to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 5 ---------------
__global__ void saxpy_kernel(int n, float a, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, const float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate device memory
    cudaMalloc(&d_x, size);
    cudaMalloc(&d_y, size);

    // Copy host memory to device memory
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Thread block size
    int blockSize = 256;
    // Number of thread blocks in the grid
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the CUDA kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy the result back to the host memory
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 6 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    // Get the global index of the thread
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    // Ensure within array bounds
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float *x, float *y) {
    // Device pointers
    float *d_x, *d_y;
    
    // Allocate memory on the device
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    
    // Define the block size and number of blocks
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    
    // Launch the kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);
    
    // Copy the result back from device to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 7 ---------------
__global__ void saxpy_parallel(int n, float a, float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, float* x, float* y) {
    float *d_x, *d_y;
    
    // Allocate device memory
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    
    // Define block size and grid size
    int blockSize = 256; // Number of threads per block
    int gridSize = (n + blockSize - 1) / blockSize; // Number of blocks in grid
    
    // Launch the kernel
    saxpy_parallel<<<gridSize, blockSize>>>(n, a, d_x, d_y);
    
    // Copy the result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 8 ---------------
__global__ void saxpy_kernel(int n, float a, float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float* x, float* y) {
    float *d_x, *d_y;

    // Allocate memory on the GPU
    cudaMalloc(&d_x, n * sizeof(float));
    cudaMalloc(&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Define block size and grid size
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch the SAXPY kernel
    saxpy_kernel<<<gridSize, blockSize>>>(n, a, d_x, d_y);

    // Copy the result back to the host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free the GPU memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 9 ---------------
__global__ void saxpy_kernel(int n, float a, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate memory on the device
    cudaMalloc(&d_x, size);
    cudaMalloc(&d_y, size);

    // Copy vectors from host memory to device memory
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Define thread block size and grid size
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the CUDA Kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result from device memory to host memory
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 10 ---------------
__global__ void saxpy_kernel(int n, float a, float* x, float* y) {
    int index = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;
    
    for (int i = index; i < n; i += stride) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_parallel(int n, float a, float* x, float* y) {
    float *d_x, *d_y;
    
    // Allocate device memory
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    
    // Number of blocks and threads per block
    int blockSize = 256; // Usually it's a good idea to experiment with this for optimal performance
    int numBlocks = (n + blockSize - 1) / blockSize;
    
    // Launch kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);
    
    // Wait for GPU to finish the work
    cudaDeviceSynchronize();
    
    // Copy result from device to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

