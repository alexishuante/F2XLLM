--------------- Code Block 1 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate device memory
    cudaMalloc((void**)&d_x, size);
    cudaMalloc((void**)&d_y, size);

    // Copy data from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Number of threads per block
    int threadsPerBlock = 256;
    // Compute the number of blocks
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // Launch the SAXPY kernel
    saxpy_kernel<<<blocksPerGrid, threadsPerBlock>>>(n, a, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 2 ---------------
__global__ void saxpy_kernel(int n, float a, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, const float *x, float *y) {
    // Set up for CUDA grid and block dimensions
    int blockSize = 256;  // Block size can be tuned for the device
    int numBlocks = (n + blockSize - 1) / blockSize;
    
    // Device pointers
    float *d_x, *d_y;
    
    // Allocate device memory
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    
    // Launch the SAXPY kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);
    
    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 3 ---------------
__global__ void saxpy_kernel(int n, float a, const float * __restrict__ x, float * y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, const float *x, float *y) {
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Allocate device memory
    float *d_x, *d_y;
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 4 ---------------
__global__ void saxpy(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_host(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);
    
    // Allocate device memory
    cudaMalloc((void**)&d_x, size);
    cudaMalloc((void**)&d_y, size);
    
    // Copy data from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);
    
    // Set up execution configuration
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    
    // Launch the CUDA kernel
    saxpy<<<numBlocks, blockSize>>>(n, a, d_x, d_y);
    
    // Copy data from device to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 5 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate memory on the device
    cudaMalloc((void **)&d_x, size);
    cudaMalloc((void **)&d_y, size);

    // Copy input vectors from host memory to device memory
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Define the number of blocks and threads per block
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the CUDA kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result vector from device memory to host memory
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 6 ---------------
__global__ void saxpy(int n, float a, const float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_cuda(int n, float a, const float* x, float* y) {
    // Determine block size and number of blocks
    int blockSize = 256; // Threads per block
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Allocate device memory
    float *d_x, *d_y;
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch CUDA kernel
    saxpy<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 7 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, float *x, float *y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);
    
    // Allocate memory on the device
    cudaMalloc((void**)&d_x, size);
    cudaMalloc((void**)&d_y, size);
    
    // Copy input vectors from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);
    
    // Define the block size and grid size
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    
    // Launch the SAXPY kernel
    saxpy_kernel<<<gridSize, blockSize>>>(n, a, d_x, d_y);
    
    // Synchronize the device
    cudaDeviceSynchronize();
    
    // Copy result vector from device to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);
    
    // Free the allocated memory on the device
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 8 ---------------
__global__ void saxpy_kernel(int n, float a, const float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, const float* x, float* y) {
    float *d_x, *d_y;
    size_t size = n * sizeof(float);

    // Allocate memory on the GPU
    cudaMalloc((void**)&d_x, size);
    cudaMalloc((void**)&d_y, size);

    // Copy arrays from host to device
    cudaMemcpy(d_x, x, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, size, cudaMemcpyHostToDevice);

    // Launch the kernel with enough blocks to cover all elements
    int blockSize = 256; // You might optimize this number
    int numBlocks = (n + blockSize - 1) / blockSize;
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 9 ---------------
__global__ void saxpy_kernel(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy(int n, float a, float *x, float *y) {
    // Device pointers
    float *d_x, *d_y;

    // Allocate memory on the device
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Number of threads per block
    int blockSize = 256;
    // Number of blocks per grid
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the SAXPY kernel
    saxpy_kernel<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy the result back to the host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free the device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

--------------- Code Block 10 ---------------
__global__ void saxpy(int n, float a, float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        y[i] = a * x[i] + y[i];
    }
}

void saxpy_host(int n, float a, float *x, float *y) {
    // Define number of threads and blocks
    int blockSize = 256;                      // Number of threads per block
    int numBlocks = (n + blockSize - 1) / blockSize;  // Number of blocks

    // Allocate device memory
    float *d_x, *d_y;
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the SAXPY kernel on the device
    saxpy<<<numBlocks, blockSize>>>(n, a, d_x, d_y);

    // Copy the result back to the host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_x);
    cudaFree(d_y);
}

