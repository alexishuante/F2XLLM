--------------- Code Block 1 ---------------
__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        int idx = i + n * (j + n * k);
        int idx_im1 = (i-1) + n * (j + n * k);
        int idx_ip1 = (i+1) + n * (j + n * k);
        int idx_jm1 = i + n * ((j-1) + n * k);
        int idx_jp1 = i + n * ((j+1) + n * k);
        int idx_km1 = i + n * (j + n * (k-1));
        int idx_kp1 = i + n * (j + n * (k+1));

        unew[idx] = 0.125 * (u[idx_im1] + u[idx_ip1] + u[idx_jm1] + u[idx_jp1] +
                             u[idx_km1] + u[idx_kp1] + u[idx]);
    }
}

void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u, *d_unew;

    size_t size = n * n * n * sizeof(double);
    
    // Allocate memory on the GPU
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy data to GPU
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    // Define block and grid dimensions
    dim3 blockSize(8, 8, 8);
    dim3 gridSize((n+blockSize.x-1)/blockSize.x, (n+blockSize.y-1)/blockSize.y, 
                  (n+blockSize.z-1)/blockSize.z);

    for (int iter = 0; iter < niter; iter++) {
        // Launch the HIP kernel
        hipLaunchKernelGGL(jacobi_kernel, gridSize, blockSize, 0, 0, d_u, d_unew, n);

        // Swap pointers for the next iteration
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy result back to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free GPU memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 2 ---------------
__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        int idx = i + n * (j + n * k);
        unew[idx] = 0.125 * (
            u[(i-1) + n * (j + n * k)] + u[(i+1) + n * (j + n * k)] +
            u[i + n * ((j-1) + n * k)] + u[i + n * ((j+1) + n * k)] +
            u[i + n * (j + n * (k-1))] + u[i + n * (j + n * (k+1))] + 
            u[idx]
        );
    }
}

void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u, *d_unew;

    size_t size = n * n * n * sizeof(double);

    // Allocate device memory
    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    // Copy initial data from host to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    // Define grid and block dimensions
    dim3 block(8, 8, 8);
    dim3 grid((n + block.x - 1) / block.x, (n + block.y - 1) / block.y, (n + block.z - 1) / block.z);

    for (int iter = 0; iter < niter; ++iter) {
        // Launch the Jacobi kernel
        hipLaunchKernelGGL(jacobi_kernel, grid, block, 0, 0, d_u, d_unew, n);

        // Synchronize after kernel completion
        hipDeviceSynchronize();

        // Swap the arrays
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy the result back to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 3 ---------------
__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i - 1, j, k, n)] + u[IDX(i + 1, j, k, n)] +
                                          u[IDX(i, j - 1, k, n)] + u[IDX(i, j + 1, k, n)] +
                                          u[IDX(i, j, k - 1, n)] + u[IDX(i, j, k + 1, n)] +
                                          u[IDX(i, j, k, n)]);
    }
}

void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u;
    double *d_unew;

    size_t size = n * n * n * sizeof(double);
    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n - 2 + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n - 2 + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n - 2 + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; ++iter) {
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);
        hipDeviceSynchronize();
        double* t = d_u;
        d_u = d_unew;
        d_unew = t;
    }

    // Copy the result back to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);
  
    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 4 ---------------
__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockDim.x * blockIdx.x + threadIdx.x + 1;
    int j = blockDim.y * blockIdx.y + threadIdx.y + 1;
    int k = blockDim.z * blockIdx.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i - 1, j, k, n)] + u[IDX(i + 1, j, k, n)] +
                                         u[IDX(i, j - 1, k, n)] + u[IDX(i, j + 1, k, n)] +
                                         u[IDX(i, j, k - 1, n)] + u[IDX(i, j, k + 1, n)] +
                                         u[IDX(i, j, k, n)]);
    }
}

void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate device memory
    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    // Copy data from host to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    // Specify grid and block dimensions
    dim3 dimBlock(8, 8, 8); // Adjust based on your specific GPU architecture
    dim3 dimGrid((n + dimBlock.x - 3) / dimBlock.x, 
                 (n + dimBlock.y - 3) / dimBlock.y, 
                 (n + dimBlock.z - 3) / dimBlock.z);

    for (int iter = 0; iter < niter; ++iter) {
        // Launch the Jacobi kernel
        hipLaunchKernelGGL(jacobi_kernel, dimGrid, dimBlock, 0, 0, d_u, d_unew, n);

        // Swap the pointers for next iteration
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy result from device to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 5 ---------------
__global__ void jacobi_kernel(const REAL* __restrict__ u, REAL* __restrict__ unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        int idx = k * n * n + j * n + i; // 1D index for (i, j, k) in 3D array
        unew[idx] = 0.125 * (u[idx - 1] + u[idx + 1] + u[idx - n] + u[idx + n] +
                             u[idx - n * n] + u[idx + n * n] + u[idx]);
    }
}

void jacobi_parallel(REAL* u, REAL* unew, int n, int niter) {
    size_t size = n * n * n * sizeof(REAL);
    
    // Device memory allocation
    REAL *d_u, *d_unew;
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy initial data from host to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);

    // Define the block size and grid size
    dim3 blockDim(8, 8, 8);
    dim3 gridDim((n + blockDim.x - 1) / blockDim.x, 
                 (n + blockDim.y - 1) / blockDim.y, 
                 (n + blockDim.z - 1) / blockDim.z);

    for (int iter = 0; iter < niter; iter++) {
        // Launch the Jacobi kernel
        hipLaunchKernelGGL(jacobi_kernel, gridDim, blockDim, 0, 0, d_u, d_unew, n);

        // Swap the pointers for the next iteration
        REAL* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy the result from device to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 6 ---------------
__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[IDX(i, j, k, n)] = 0.125 * (u[IDX(i-1, j, k, n)] + u[IDX(i+1, j, k, n)] +
                                         u[IDX(i, j-1, k, n)] + u[IDX(i, j+1, k, n)] +
                                         u[IDX(i, j, k-1, n)] + u[IDX(i, j, k+1, n)] +
                                         u[IDX(i, j, k, n)]);
    }
}

void jacobi_parallel(double *u, double *unew, int n, int niter) {
    double *d_u, *d_unew;

    size_t size = n * n * n * sizeof(double);

    // Allocate device memory
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    // Copy memory from host to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 blocksPerGrid((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                       (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                       (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; iter++) {
        // Launch kernel
        hipLaunchKernelGGL(jacobi_kernel, blocksPerGrid, threadsPerBlock, 0, 0, d_u, d_unew, n);

        // Swap pointers
        double *temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy memory from device to host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 7 ---------------
__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i >= 2 && i < (n - 1) && j >= 2 && j < (n - 1) && k >= 2 && k < (n - 1)) {
        unew[INDEX(i, j, k, n)] = 0.125 * (
            u[INDEX(i-1, j, k, n)] + u[INDEX(i+1, j, k, n)] +
            u[INDEX(i, j-1, k, n)] + u[INDEX(i, j+1, k, n)] +
            u[INDEX(i, j, k-1, n)] + u[INDEX(i, j, k+1, n)] +
            u[INDEX(i, j, k, n)]
        );
    }
}

void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate memory on the GPU
    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    // Copy the input arrays to the GPU
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; ++iter) {
        // Launch the kernel
        hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n);

        // Swap the pointers
        double *temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy the result back to the host
    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    // Free GPU memory
    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 8 ---------------
__global__ void jacobi_kernel(const double *u, double *unew, int n, int niter) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        for (int iter = 0; iter < niter; ++iter) {
            unew[i*n*n + j*n + k] = 0.125 * (
                u[(i-1)*n*n + j*n + k] +
                u[(i+1)*n*n + j*n + k] +
                u[i*n*n + (j-1)*n + k] +
                u[i*n*n + (j+1)*n + k] +
                u[i*n*n + j*n + (k-1)] +
                u[i*n*n + j*n + (k+1)] +
                u[i*n*n + j*n + k]
            );
        }
    }
}

extern "C"
void jacobi_parallel(double *u, double *unew, int n, int niter) {
    size_t size = n * n * n * sizeof(double);
    
    double *d_u, *d_unew;
    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y,
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    hipLaunchKernelGGL(jacobi_kernel, numBlocks, threadsPerBlock, 0, 0, d_u, d_unew, n, niter);

    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);
    hipMemcpy(unew, d_unew, size, hipMemcpyDeviceToHost);

    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 9 ---------------
__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        unew[IDX3D(i, j, k, n)] = 0.125 * (u[IDX3D(i-1, j, k, n)] + u[IDX3D(i+1, j, k, n)] +
                                            u[IDX3D(i, j-1, k, n)] + u[IDX3D(i, j+1, k, n)] +
                                            u[IDX3D(i, j, k-1, n)] + u[IDX3D(i, j, k+1, n)] +
                                            u[IDX3D(i, j, k, n)]);
    }
}

void jacobi_parallel(double *u, double *unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    hipMalloc((void**)&d_u, size);
    hipMalloc((void**)&d_unew, size);

    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    dim3 blockDim(8, 8, 8);
    dim3 gridDim((n + blockDim.x - 1) / blockDim.x,
                 (n + blockDim.y - 1) / blockDim.y,
                 (n + blockDim.z - 1) / blockDim.z);

    for (int iter = 0; iter < niter; iter++) {
        hipLaunchKernelGGL(jacobi_kernel, gridDim, blockDim, 0, 0, d_u, d_unew, n);
        hipDeviceSynchronize();

        // Swap pointers
        double *temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    hipMemcpy(u, d_u, size, hipMemcpyDeviceToHost);

    hipFree(d_u);
    hipFree(d_unew);
}

--------------- Code Block 10 ---------------
__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;
    
    if (i < n-1 && j < n-1 && k < n-1) {
        unew[(i * n * n) + (j * n) + k] = 0.125 * (
            u[((i-1) * n * n) + (j * n) + k] + 
            u[((i+1) * n * n) + (j * n) + k] + 
            u[(i * n * n) + ((j-1) * n) + k] +
            u[(i * n * n) + ((j+1) * n) + k] + 
            u[(i * n * n) + (j * n) + (k-1)] + 
            u[(i * n * n) + (j * n) + (k+1)] + 
            u[(i * n * n) + (j * n) + k]);
    }
}

void jacobi_parallel(double *u, double *unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    // Allocate device memory
    hipMalloc(&d_u, size);
    hipMalloc(&d_unew, size);

    // Copy data to device
    hipMemcpy(d_u, u, size, hipMemcpyHostToDevice);
    hipMemcpy(d_unew, unew, size, hipMemcpyHostToDevice);

    // Define block and grid dimensions
    dim3 blockDim(8, 8, 8); 
    dim3 gridDim((n+blockDim.x-2)/blockDim.x, (n+blockDim.y-2)/blockDim.y, (n+blockDim.z-2)/blockDim.z);

    // Iteratively apply the Jacobi operation
    for (int iter = 0; iter < niter; iter++) {
        hipLaunchKernelGGL(jacobi_kernel, gridDim, blockDim, 0, 0, d_u, d_unew, n);
        hipMemcpy(d_u, d_unew, size, hipMemcpyDeviceToDevice);
    }
    
    // Copy result back to host
    hipMemcpy(u, d_unew, size, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_u);
    hipFree(d_unew);
}

