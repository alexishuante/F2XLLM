Code Block 1:
void hipErrorCheck(hipError_t err, const char* file, int line) {
    if (err != hipSuccess) {
        std::cerr << "HIP error at " << file << " " << line << ": " << hipGetErrorString(err) << std::endl;
        exit(err);
    }
}

__global__ void spmvKernel(int n, int nnz, const float* __restrict__ val, 
                            const int* __restrict__ row, const int* __restrict__ col,
                            const float* __restrict__ x, float* __restrict__ y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float temp = 0.0;
        for (int j = row[i]; j < row[i+1]; ++j) {
            temp += val[j] * x[col[j]];
        }
        y[i] = temp;
    }
}

Code Block 2:
void spmv_parallel(int n, int nnz, const std::vector<int>& row, const std::vector<int>& col, const std::vector<float>& val, const std::vector<float>& x, std::vector<float>& y) {
    // Device pointers
    int *d_row, *d_col;
    float *d_val, *d_x, *d_y;

    // Allocate device memory
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));
    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));

    // Copy data from host to device
    hipMemcpy(d_row, row.data(), (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col.data(), nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_val, val.data(), nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x.data(), n * sizeof(float), hipMemcpyHostToDevice);

    // Kernel launch parameters
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch HIP kernel
    hipLaunchKernelGGL(spmv_kernel, numBlocks, blockSize, 0, 0, n, d_row, d_col, d_val, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y.data(), d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, const int* __restrict__ row, const int* __restrict__ col, const float* __restrict__ val, const float* __restrict__ x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 3:
void spmv_parallel(int n, int nnz, const std::vector<float> &val, const std::vector<int> &row, const std::vector<int> &col, const std::vector<float> &x, std::vector<float> &y) {
    // Allocate device memory
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));

    // Copy data from host to device
    hipMemcpy(d_val, val.data(), nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x.data(), n * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row.data(), (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col.data(), nnz * sizeof(int), hipMemcpyHostToDevice);

    // Launch kernel
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    hipLaunchKernelGGL(spmv_kernel, dim3(gridSize), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy results back to host
    hipMemcpy(y.data(), d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
    hipFree(d_row);
    hipFree(d_col);
}

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= n) return;

    float temp = 0.0;
    for (int j = row[i]; j < row[i + 1]; ++j) {
        temp += val[j] * x[col[j]];
    }
    y[i] = temp;
}

Code Block 4:
void spmv_parallel(int n, int nnz, const std::vector<float>& val, const std::vector<int>& row, const std::vector<int>& col, const std::vector<float>& x, std::vector<float>& y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    size_t size_val = nnz * sizeof(float);
    size_t size_x = n * sizeof(float);
    size_t size_y = n * sizeof(float);
    size_t size_row = (n + 1) * sizeof(int);
    size_t size_col = nnz * sizeof(int);

    // Allocate device memory
    hipMalloc((void**)&d_val, size_val);
    hipMalloc((void**)&d_x, size_x);
    hipMalloc((void**)&d_y, size_y);
    hipMalloc((void**)&d_row, size_row);
    hipMalloc((void**)&d_col, size_col);

    // Copy data to device
    hipMemcpy(d_val, val.data(), size_val, hipMemcpyHostToDevice);
    hipMemcpy(d_x, x.data(), size_x, hipMemcpyHostToDevice);
    hipMemcpy(d_row, row.data(), size_row, hipMemcpyHostToDevice);
    hipMemcpy(d_col, col.data(), size_col, hipMemcpyHostToDevice);

    // Launch the kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;
    hipLaunchKernelGGL(spmv_kernel, dim3(blocksPerGrid), dim3(threadsPerBlock), 0, 0, n, d_val, d_row, d_col, d_x, d_y);

    // Copy the result back to host
    hipMemcpy(y.data(), d_y, size_y, hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
    hipFree(d_row);
    hipFree(d_col);
}

__global__ void spmv_kernel(int n, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 5:
void spmv_parallel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    // Device memory pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));

    // Copy data from host to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);

    // Set up execution configuration
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch kernel
    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float* __restrict__ val, const int* __restrict__ row,
                            const int* __restrict__ col, const float* __restrict__ x, float* __restrict__ y) {
    // Get the row index
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 6:
void spmv_parallel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    // Device pointers
    float* d_val;
    int* d_row;
    int* d_col;
    float* d_x;
    float* d_y;

    // Allocate device memory
    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));

    // Copy data to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);

    // Launch kernel
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 7:
void spmv_parallel(int n, int nnz, const std::vector<float>& val, const std::vector<int>& row, const std::vector<int>& col, const std::vector<float>& x, std::vector<float>& y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_row, (n + 1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));

    hipMemcpy(d_val, val.data(), nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row.data(), (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col.data(), nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x.data(), n * sizeof(float), hipMemcpyHostToDevice);

    int blockSize = 256; // You can adjust this number.
    int numBlocks = (n + blockSize - 1) / blockSize;

    hipLaunchKernelGGL(spmv_kernel, dim3(numBlocks), dim3(blockSize), 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    hipMemcpy(y.data(), d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__ void spmv_kernel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 8:
void spmv_parallel(int n, int nnz, const std::vector<float>& val, const std::vector<int>& row, const std::vector<int>& col, const std::vector<float>& x, std::vector<float>& y) {
    // Allocate device memory
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));

    // Copy data to device
    hipMemcpy(d_val, val.data(), nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x.data(), n * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row.data(), (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col.data(), nnz * sizeof(int), hipMemcpyHostToDevice);

    // Launch the kernel
    int blockSize = 256; // 256 threads per block
    int numBlocks = (n + blockSize - 1) / blockSize;
    hipLaunchKernelGGL(spmv_kernel, numBlocks, blockSize, 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    hipMemcpy(y.data(), d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
    hipFree(d_row);
    hipFree(d_col);
}

__global__ void spmv_kernel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float yi = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            yi += val[j] * x[col[j]];
        }
        y[i] = yi;
    }
}

Code Block 9:
void spmv_parallel(int n, int nnz, const float* val, const int* row, const int* col, const float* x, float* y) {
    // Device memory pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;
    
    // Allocate device memory
    hipMalloc(&d_val, nnz * sizeof(float));
    hipMalloc(&d_x, n * sizeof(float));
    hipMalloc(&d_y, n * sizeof(float));
    hipMalloc(&d_row, (n + 1) * sizeof(int));
    hipMalloc(&d_col, nnz * sizeof(int));
    
    // Copy data to device
    hipMemcpy(d_val, val, nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x, n * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row, (n + 1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col, nnz * sizeof(int), hipMemcpyHostToDevice);
    
    // Launch the kernel with appropriate block and grid sizes
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    
    hipLaunchKernelGGL(spmv_kernel, dim3(gridSize), dim3(blockSize), 0, 0, n, d_val, d_row, d_col, d_x, d_y);
    
    // Copy result from device to host
    hipMemcpy(y, d_y, n * sizeof(float), hipMemcpyDeviceToHost);
    
    // Free device memory
    hipFree(d_val);
    hipFree(d_x);
    hipFree(d_y);
    hipFree(d_row);
    hipFree(d_col);
}

__global__ void spmv_kernel(int n, const float* __restrict__ val, const int* __restrict__ row, const int* __restrict__ col, const float* __restrict__ x, float* __restrict__ y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

Code Block 10:
void spmv_parallel(int n, int nnz, const std::vector<float> &val, const std::vector<int> &row, 
                   const std::vector<int> &col, const std::vector<float> &x, std::vector<float> &y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    hipMalloc((void**)&d_val, nnz * sizeof(float));
    hipMalloc((void**)&d_row, (n+1) * sizeof(int));
    hipMalloc((void**)&d_col, nnz * sizeof(int));
    hipMalloc((void**)&d_x, n * sizeof(float));
    hipMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    hipMemcpy(d_val, val.data(), nnz * sizeof(float), hipMemcpyHostToDevice);
    hipMemcpy(d_row, row.data(), (n+1) * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_col, col.data(), nnz * sizeof(int), hipMemcpyHostToDevice);
    hipMemcpy(d_x, x.data(), n * sizeof(float), hipMemcpyHostToDevice);
    
    // Define block and grid sizes
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    
    // Launch kernel
    hipLaunchKernelGGL(spmv_kernel, gridSize, blockSize, 0, 0, n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result from device to host
    hipMemcpy(y.data(), d_y, n * sizeof(float), hipMemcpyDeviceToHost);

    // Free device memory
    hipFree(d_val);
    hipFree(d_row);
    hipFree(d_col);
    hipFree(d_x);
    hipFree(d_y);
}

__global__
void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i+1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

