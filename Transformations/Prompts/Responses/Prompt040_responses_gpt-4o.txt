Output 1:
The subroutine you've provided in Fortran and OpenACC can be translated to C and CUDA. Below is an equivalent function using CUDA to perform Sparse matrix–vector multiplication (SpMV). Note that, like the original Fortran code, this function assumes that the matrix is stored in Compressed Sparse Row (CSR) format.

```c
#include <cuda_runtime.h>
#include <stdio.h>

// Kernel to perform SpMV
__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float temp = 0.0;
        for (int j = row[i]; j < row[i + 1]; j++) {
            temp += val[j] * x[col[j]];
        }
        y[i] = temp;
    }
}

// Host function to call the kernel
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Pointers for device memory
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the kernel with enough threads to cover all elements in y
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy the result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

int main() {
    // Example usage
    int n = 5;  // Number of rows (and columns)
    int nnz = 13; // Number of non-zero elements

    // CSR format arrays
    float val[] = { 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130 };
    int row[] = { 0, 2, 4, 7, 9, 13 };
    int col[] = { 0, 2, 1, 3, 0, 2, 4, 1, 4, 0, 1, 3, 4 };
    float x[] = { 1, 2, 3, 4, 5 };
    float y[5];

    // Run the SpMV
    spmv_parallel(n, nnz, val, row, col, x, y);

    // Print the result
    for (int i = 0; i < n; i++) {
        printf("y[%d] = %f\n", i, y[i]);
    }

    return 0;
}
```

### Explanation:
1. **CUDA Kernel**:
   - The kernel function `spmv_kernel` performs the SpMV. Each thread computes one element of the result vector `y`.
   - The loop inside the kernel iterates over the non-zero elements corresponding to each row.

2. **Host Function**:
   - The function `spmv_parallel` allocates memory on the GPU, copies the data from the host to the device, launches the kernel, and then copies the result back to the host.
   - The execution configuration (`<<<numBlocks, blockSize>>>`) ensures that all elements of the result vector `y` are covered by the available threads.

3. **Main Function**:
   - The `main` function provides an example usage of the `spmv_parallel` function.

### Notes:
- Adjust the `blockSize` as necessary, considering the GPU's capability.
- Error checking has been omitted for brevity. In production code, always check for errors after CUDA API calls.
- The indexing in C (0-based) vs. Fortran (1-based) has been taken into account.

Output 2:
Certainly! Here is the equivalent Sparse matrix–vector multiplication (SpMV) operation implemented in C and CUDA. The Fortran code you provided computes `y = A * x` where `A` is a sparse matrix stored in Compressed Sparse Row (CSR) format.

### CUDA implementation:
A key point is to ensure efficient use of GPU resources and manage memory transfers between the host (CPU) and device (GPU).

#### CUDA C Function:
```c
#include <stdio.h>
#include <cuda_runtime.h>

// Kernel function to compute SpMV
__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

// Host function for Sparse Matrix-Vector Multiplication
void spmv_parallel(int n, int nnz, const float *h_val, const int *h_row, const int *h_col, const float *h_x, float *h_y) {
    // Device memory pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data to device
    cudaMemcpy(d_val, h_val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, h_row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, h_col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, h_x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Set up execution configuration
    int blockSize = 256;  // Number of threads in each thread block
    int numBlocks = (n + blockSize - 1) / blockSize;

    // Launch the kernel
    spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(h_y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

int main() {
    // Example usage
    int n = 5;
    int nnz = 13;
    float h_val[13] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0};
    int h_row[6] = {0, 3, 4, 7, 10, 13};
    int h_col[13] = {0, 1, 4, 1, 0, 2, 4, 0, 3, 4, 1, 2, 3};
    float h_x[5] = {1.0, 1.0, 1.0, 1.0, 1.0};
    float h_y[5];

    spmv_parallel(n, nnz, h_val, h_row, h_col, h_x, h_y);
    
    // Print the result
    for (int i = 0; i < n; i++) {
        printf("%f ", h_y[i]);
    }
    printf("\n");

    return 0;
}
```

### Explanation:
1. **CUDA Kernel (`spmv_kernel`)**:
   - Each thread is assigned a row index `i`.
   - Computes the dot product for the `i`-th row of the matrix and the input vector `x`.

2. **Host Function (`spmv_parallel`)**:
   - Allocates memory on the GPU for inputs and outputs.
   - Copies data from host to device memory.
   - Launches the CUDA kernel.
   - Copies the result back to host memory.
   - Frees GPU memory.

3. **Example Main Function**:
   - Demonstrates how to initialize data and call the `spmv_parallel` function.
   - Masks a simple test case with 5 rows and 13 non-zeros.

The CUDA implementation can efficiently utilize GPU resources to perform parallel calculations for the sparse matrix-vector multiplication. When dealing with larger matrices, the performance benefits from GPU acceleration become more noticeable.

Output 3:
Sure, below is the equivalent code to implement the Sparse Matrix-Vector Multiplication (SpMV) in C using CUDA. This code will leverage CUDA's parallel computing capabilities to achieve a similar result to the OpenACC version written in Fortran.

### Fortran with OpenACC

Here is your provided Fortran code for reference:

```fortran
subroutine spmv_parallel(n, nnz, val, row, col, x, y)
    integer, intent(in) :: n, nnz
    real, intent(in) :: val(nnz), x(n)
    integer, intent(in) :: row(n+1), col(nnz)
    real, intent(out) :: y(n)
    integer i, j
    !$ACC PARALLEL LOOP DEFAULT(PRESENT) COPYIN(val, row, col, x) COPYOUT(y)
    do i = 1, n
      y(i) = 0.0
      do j = row(i), row(i+1)-1
        y(i) = y(i) + val(j) * x(col(j))
      enddo
    enddo
    !$ACC END PARALLEL LOOP
end subroutine spmv_parallel
```

### C with CUDA

Here's the equivalent implementation in C using CUDA. The kernel function `spmv_kernel` performs the SpMV operation, and the main function initializes data and launches the CUDA kernel.

```c
#include <stdio.h>
#include <cuda_runtime.h>

// CUDA SpMV Kernel
__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

// Host function to call the CUDA kernel
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Allocate device memory
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);

    // Launch the CUDA kernel
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    spmv_kernel<<<gridSize, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy the result from device to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_x);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_y);
}

int main() {
    // Example inputs
    int n = 2;
    int nnz = 4;
    float val[] = {10, 20, 30, 40};
    int row[] = {0, 2, 4};
    int col[] = {0, 1, 0, 1};
    float x[] = {1, 2};
    float y[2];

    // Call the SpMV function
    spmv_parallel(n, nnz, val, row, col, x, y);

    // Print the result
    for (int i = 0; i < n; i++) {
        printf("%f ", y[i]);
    }
    printf("\n");

    return 0;
}
```

### Explanation

1. **Kernel Function**: The `spmv_kernel` function is the CUDA kernel that runs on the GPU. Each thread computes one entry of the result vector `y`.

2. **Memory Allocation**: Memory is allocated for the vectors and matrices on the GPU using `cudaMalloc`.

3. **Data Transfer**: Data is copied from host to device using `cudaMemcpy`.

4. **Kernel Launch**: The kernel is launched with a grid of blocks, each containing a number of threads.

5. **Result Transfer and Cleanup**: After the computation, the result is copied back to the host, and the device memory is freed.

This C/CUDA implementation follows a similar logic to the Fortran/OpenACC version you provided, but is adapted to fit CUDA's execution model and syntax.

Output 4:
Below is the equivalent implementation of the given Fortran + OpenACC subroutine in C and CUDA. The function `spmv_parallel` performs a Sparse matrix-vector multiplication (SpMV) operation. 

### C and CUDA Implementation:

```c
#include <cuda_runtime.h>
#include <stdio.h>

// Define a CUDA kernel for Sparse Matrix-Vector Multiplication
__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

// Host function to launch the CUDA kernel
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void **)&d_val, nnz * sizeof(float));
    cudaMalloc((void **)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void **)&d_col, nnz * sizeof(int));
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));

    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    // Determine block size and grid size
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;

    // Launch the CUDA kernel
    spmv_kernel<<<gridSize, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy result from device to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

int main() {
    // Example usage of the spmv_parallel function
    // Supposed values for a small example sparse matrix

    int n = 4;
    int nnz = 9;
    float val[] = {10, 20, 30, 40, 50, 60, 70, 80, 90};
    int row[] = {0, 2, 4, 7, 9};
    int col[] = {0, 1, 0, 3, 1, 2, 3, 2, 3};
    float x[] = {1, 2, 3, 4};
    float y[4];

    spmv_parallel(n, nnz, val, row, col, x, y);

    // Print the result
    for (int i = 0; i < n; i++) {
        printf("%f\n", y[i]);
    }

    return 0;
}
```

### Explanation:

1. **Kernel definition (`spmv_kernel`)**:
    - The kernel function computes the SpMV operation. Each thread is responsible for calculating one entry of the resulting vector `y`.
    - The sum for each row `i` is initialized to 0. Then the values are accumulated in a loop running from `row[i]` to `row[i + 1] - 1`.

2. **Host function (`spmv_parallel`)**:
    - Device memory is allocated for all required arrays.
    - Data from host arrays is copied to the corresponding device arrays.
    - The CUDA kernel `spmv_kernel` is launched with an appropriate block and grid size.
    - Results are copied back from device to host.
    - Device memory is freed.

3. **Main function**:
    - Provides example inputs and calls the `spmv_parallel` function to demonstrate its usage.
    - Prints the resulting vector `y` after the SpMV operation.

Make sure to compile with the appropriate CUDA compiler (`nvcc`), for example:
```sh
nvcc -o spmv_demo spmv_demo.cu
```

Output 5:
Below is the C and CUDA implementation of the Sparse matrix–vector multiplication (SpMV) operation equivalent to the provided Fortran and OpenACC code.

### C Implementation:
```c
#include <stdio.h>

void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    for (int i = 0; i < n; i++) {
        y[i] = 0.0;
        for (int j = row[i]; j < row[i+1]; j++) {
            y[i] += val[j] * x[col[j]];
        }
    }
}

int main() {
    int n = 4;
    int nnz = 9;
    
    float val[] = {10, 20, 30, 40, 50, 60, 70, 80, 90};
    int row[] = {0, 3, 4, 7, 9};
    int col[] = {0, 1, 2, 3, 0, 2, 3, 1, 3};
    float x[] = {1, 2, 3, 4};
    float y[4];

    spmv_parallel(n, nnz, val, row, col, x, y);

    for (int i = 0; i < n; i++) {
        printf("%f\n", y[i]);
    }

    return 0;
}
```

### CUDA Implementation:
```cuda
#include <stdio.h>
#include <cuda_runtime.h>

__global__ void spmv_parallel_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < n) {
        y[i] = 0.0;
        for (int j = row[i]; j < row[i + 1]; j++) {
            y[i] += val[j] * x[col[j]];
        }
    }
}

void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n+1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    spmv_parallel_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

int main() {
    int n = 4;
    int nnz = 9;

    float val[] = {10, 20, 30, 40, 50, 60, 70, 80, 90};
    int row[] = {0, 3, 4, 7, 9};
    int col[] = {0, 1, 2, 3, 0, 2, 3, 1, 3};
    float x[] = {1, 2, 3, 4};
    float y[4];

    spmv_parallel(n, nnz, val, row, col, x, y);

    for (int i = 0; i < n; i++) {
        printf("%f\n", y[i]);
    }

    return 0;
}
```

### Key Differences:
1. **Explicit Memory Management**: CUDA requires explicit memory allocation, memory transfer between host and device, and memory deallocation.
2. **Kernel Launch**: CUDA uses kernel functions that are executed on the GPU using specified grid and block sizes.

### Simplified Explanation for the CUDA Code:
- **Memory Allocation**: Allocate memory on the GPU for necessary arrays (`val`, `row`, `col`, `x`, `y`).
- **Memory Transfer**: Copy data from the host (CPU) to the GPU (device).
- **Kernel Execution**: Launch the `spmv_parallel_kernel`, ensuring that each thread operates on a single row of the sparse matrix.
- **Memory Transfer**: Copy the result from the GPU back to the host.
- **Memory Deallocation**: Free the previously allocated GPU memory.

This CUDA implementation closely follows the logic of both the Fortran/OpenACC code provided and the C code shown above.

Output 6:
Sure! Here is the equivalent code in C and CUDA for the given Fortran and OpenACC subroutine:

### C Code with CUDA Support:

#### main.c
```c
#include <stdio.h>
#include <stdlib.h>
#include <cuda_runtime.h>

void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y);

int main() {
    int n = 5;
    int nnz = 9;

    float val[] = {10, 20, 30, 40, 50, 60, 70, 80, 90};
    int row[] = {0, 2, 4, 6, 7, 9};
    int col[] = {0, 1, 2, 1, 3, 4, 2, 3, 4};
    float x[] = {1, 2, 3, 4, 5};
    float y[n];

    spmv_parallel(n, nnz, val, row, col, x, y);

    printf("Resultant vector y:\n");
    for (int i = 0; i < n; i++) {
        printf("%f\n", y[i]);
    }

    return 0;
}
```

#### kernel.cu
```c
#include <cuda_runtime.h>

__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float sum = 0.0;

        int row_start = row[i];
        int row_end = row[i + 1];

        for (int j = row_start; j < row_end; j++) {
            sum += val[j] * x[col[j]];
        }

        y[i] = sum;
    }
}

void spmv_parallel(int n, int nnz, float *val, int *row, int *col, float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;

    spmv_kernel<<<numBlocks, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}
```

### Explanation:
The `main.c` file sets up the sparse matrix data structures and calls the `spmv_parallel` function.

In `kernel.cu`, the `spmv_kernel` CUDA kernel performs the sparse matrix-vector multiplication. The `spmv_parallel` function handles memory allocation, cudaMemcpy operations to transfer data to and from the GPU, kernel launch, and cleanup.

Compile and run both files together using the following commands:
```sh
nvcc main.c kernel.cu -o spmv_program
./spmv_program
```
This code replicates the logic of the provided Fortran subroutine using CUDA for parallel execution on a GPU.

Output 7:
To implement the sparse matrix-vector multiplication (SpMV) in C and CUDA based on the provided Fortran and OpenACC code, we can use a CSR (Compressed Sparse Row) representation for the sparse matrix. Here's how you can translate the subroutine:

First, the C function:
```c
#include <stdio.h>

void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    for (int i = 0; i < n; ++i) {
        y[i] = 0.0;
        for (int j = row[i]; j < row[i+1]; ++j) {
            y[i] += val[j] * x[col[j]];
        }
    }
}

// Example usage
int main() {
    int n = 4;
    int nnz = 9;
    float val[] = {10, 20, 30, 40, 50, 60, 70, 80, 90};
    int row[] = {0, 3, 4, 7, 9};
    int col[] = {0, 1, 2, 1, 0, 2, 3, 1, 3};
    float x[] = {1, 2, 3, 4};
    float y[4];

    spmv_parallel(n, nnz, val, row, col, x, y);

    for (int i = 0; i < n; ++i) {
        printf("%f\n", y[i]);
    }

    return 0;
}
```

Next, the CUDA equivalent:
```cuda
#include <stdio.h>

__global__ void spmv_kernel(int n, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i >= n) return;

    y[i] = 0.0;
    for (int j = row[i]; j < row[i+1]; ++j) {
        y[i] += val[j] * x[col[j]];
    }
}

void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n+1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));

    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n+1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);

    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    spmv_kernel<<<numBlocks, blockSize>>>(n, d_val, d_row, d_col, d_x, d_y);

    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}

// Example usage
int main() {
    int n = 4;
    int nnz = 9;
    float val[] = {10, 20, 30, 40, 50, 60, 70, 80, 90};
    int row[] = {0, 3, 4, 7, 9};
    int col[] = {0, 1, 2, 1, 0, 2, 3, 1, 3};
    float x[] = {1, 2, 3, 4};
    float y[4];

    spmv_parallel(n, nnz, val, row, col, x, y);

    for (int i = 0; i < n; ++i) {
        printf("%f\n", y[i]);
    }

    return 0;
}
```

Explanation:
1. **C Implementation**: Direct translation using nested loops to handle the `row` and `col` CSR structures. It assumes row indices start at 0.
2. **CUDA Implementation**:
   - A kernel function `spmv_kernel` uses thread indexing to handle parallel computation.
   - Memory for `val`, `row`, `col`, `x`, and `y` is allocated on the device (GPU) using `cudaMalloc`.
   - Data is copied from the host to the device using `cudaMemcpy`.
   - The kernel is launched with a calculated number of blocks and threads per block.
   - The result is copied back to the host memory.
   - Device memory is freed using `cudaFree`.

Both implementations follow the steps mentioned in your Fortran and OpenACC code. In the CUDA version, parallel computation is leveraged within the kernel with each thread computing a row of the result vector `y`.

Output 8:
Sure, here is a C and CUDA implementation of the Sparse matrix–vector multiplication (SpMV) operation based on the Fortran and OpenACC subroutine you provided.

First, let's define the function in C:

```c
#include <stdlib.h>
#include <stdio.h>

void spmv_serial(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    for (int i = 0; i < n; i++) {
        y[i] = 0.0f;
        for (int j = row[i]; j < row[i+1]; j++) {
            y[i] += val[j] * x[col[j]];
        }
    }
}
```

Now, let's implement the parallel version using CUDA:

```cuda
#include <cuda_runtime.h>
#include <stdio.h>

__global__ void spmv_kernel(int n, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i < n) {
        float temp = 0.0f;
        for (int j = row[i]; j < row[i+1]; j++) {
            temp += val[j] * x[col[j]];
        }
        y[i] = temp;
    }
}

void spmv_cuda(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));

    // Copy data to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);

    // Launch kernel
    int blockSize = 256;
    int numBlocks = (n + blockSize - 1) / blockSize;
    spmv_kernel<<<numBlocks, blockSize>>>(n, d_val, d_row, d_col, d_x, d_y);

    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_x);
    cudaFree(d_y);
    cudaFree(d_row);
    cudaFree(d_col);
}
```

In this CUDA implementation, `spmv_kernel` is the kernel function that executes on the GPU. It performs the SpMV operation in parallel by launching threads, each handling one row of the sparse matrix. The host function `spmv_cuda` handles memory allocations, copying data to the device, launching the kernel, and copying the results back to the host.

These are the steps and components needed to create a CUDA-compatible SpMV function that mirrors your Fortran and OpenACC implementation.

Output 9:
Certainly! To achieve parallel Sparse matrix-vector multiplication (SpMV) using CUDA in C, we need to map the existing Fortran and OpenACC logic into CUDA's programming paradigm. Here's how this can be done:

### CUDA Version in C

First, let's write the CUDA kernel to perform the SpMV operation. We'll create a function in C that sets up and launches this kernel.

```c
#include <stdio.h>

__global__ void spmv_cuda(const int n, const int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; ++j) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    // Device pointers
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;

    // Allocate memory on the device
    cudaMalloc((void **)&d_val, nnz * sizeof(float));
    cudaMalloc((void **)&d_x, n * sizeof(float));
    cudaMalloc((void **)&d_y, n * sizeof(float));
    cudaMalloc((void **)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void **)&d_col, nnz * sizeof(int));

    // Copy data to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, y, n * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);

    // Define thread block size and number of blocks
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

    // Launch the kernel
    spmv_cuda<<<blocksPerGrid, threadsPerBlock>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);

    // Copy the result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_val);
    cudaFree(d_x);
    cudaFree(d_y);
    cudaFree(d_row);
    cudaFree(d_col);
}

int main() {
    // Example usage
    int n = 4;
    int nnz = 9;

    float val[9] = {10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0};
    int row[5] = {0, 3, 4, 7, 9};
    int col[9] = {0, 1, 2, 1, 0, 1, 2, 1, 3};
    float x[4] = {1.0, 1.0, 1.0, 1.0};
    float y[4];

    spmv_parallel(n, nnz, val, row, col, x, y);

    for (int i = 0; i < n; ++i) {
        printf("y[%d] = %f\n", i, y[i]);
    }

    return 0;
}
```

### Explanation:
1. **Kernel Definition**: The `spmv_cuda` kernel performs the SpMV operation. Each thread computes a row of the resultant vector `y`.
2. **Memory Allocation**: Device memory is allocated for the necessary arrays.
3. **Memory Copying**: Data from the host is copied to the device before kernel execution, and the result is copied back to the host after execution.
4. **Kernel Launch**: The kernel launch parameters ensure that enough threads cover all rows of the output vector.

Compile and run this code with an appropriate CUDA compiler (e.g., `nvcc`).

### Notes:
- Ensure that your environment has CUDA installed and configured.
- Adjust thread block size and grid configuration according to the specifics of your hardware for optimal performance.
- The `main` function demonstrates usage with a small example; tailor it as needed for actual use cases.

Output 10:
Sure, here is an equivalent implementation of the Sparse matrix–vector multiplication (SpMV) operation in C and CUDA.

### C Code
```c
#include <stdlib.h>

// CUDA kernel function
__global__ void spmv_kernel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        float sum = 0.0f;
        for (int j = row[i]; j < row[i + 1]; j++) {
            sum += val[j] * x[col[j]];
        }
        y[i] = sum;
    }
}

// Host function
void spmv_parallel(int n, int nnz, const float *val, const int *row, const int *col, const float *x, float *y) {
    float *d_val, *d_x, *d_y;
    int *d_row, *d_col;
    
    // Allocate device memory
    cudaMalloc((void**)&d_val, nnz * sizeof(float));
    cudaMalloc((void**)&d_row, (n + 1) * sizeof(int));
    cudaMalloc((void**)&d_col, nnz * sizeof(int));
    cudaMalloc((void**)&d_x, n * sizeof(float));
    cudaMalloc((void**)&d_y, n * sizeof(float));
    
    // Copy data from host to device
    cudaMemcpy(d_val, val, nnz * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_row, row, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_col, col, nnz * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_x, x, n * sizeof(float), cudaMemcpyHostToDevice);
    
    // Define block size and grid size
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    
    // Launch CUDA kernel
    spmv_kernel<<<gridSize, blockSize>>>(n, nnz, d_val, d_row, d_col, d_x, d_y);
    
    // Copy result back to host
    cudaMemcpy(y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);
    
    // Free device memory
    cudaFree(d_val);
    cudaFree(d_row);
    cudaFree(d_col);
    cudaFree(d_x);
    cudaFree(d_y);
}
```

### Explanation
1. **spmv_kernel:** This is the CUDA kernel function that performs the SpMV operation.
    - Each thread is responsible for computing a single element of the output vector \( y \).
    - The `i` variable is calculated based on the block and thread indices.
    - The code iterates over the non-zero elements corresponding to the \( i \)-th row of the sparse matrix and computes the dot product.

2. **spmv_parallel:** This is the host function that:
    - Allocates memory on the GPU for the input and output arrays.
    - Copies data from the host to the device.
    - Configures the grid and block sizes and launches the CUDA kernel.
    - Copies the results back from the GPU to the host.
    - Frees the allocated GPU memory.

### Usage Example
To use this function, you should pass the necessary parameters as shown in the following example:
```c
int main() {
    int n = ...; // number of rows (and columns if square)
    int nnz = ...; // number of non-zero elements
    
    // Allocate and initialize input arrays
    float *val = (float*) malloc(nnz * sizeof(float));
    int *row = (int*) malloc((n+1) * sizeof(int));
    int *col = (int*) malloc(nnz * sizeof(int));
    float *x = (float*) malloc(n * sizeof(float));
    float *y = (float*) malloc(n * sizeof(float));
    
    // Initialize val, row, col, x as needed
    // ...

    // Call spmv_parallel
    spmv_parallel(n, nnz, val, row, col, x, y);
    
    // Process output y
    // ...

    // Free host memory
    free(val);
    free(row);
    free(col);
    free(x);
    free(y);

    return 0;
}
```

This C/CUDA implementation mirrors the behavior of the provided Fortran/OpenACC subroutine, performing the SpMV operation in parallel using GPU acceleration.

