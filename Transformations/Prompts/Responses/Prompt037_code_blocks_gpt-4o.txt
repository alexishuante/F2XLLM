Code Block 1:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    int i, j, k, iter;
    
    #pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
    {
        for (iter = 0; iter < niter; iter++) {
            #pragma omp for schedule(static)
            for (k = 1; k < n - 1; k++) {
                for (j = 1; j < n - 1; j++) {
                    for (i = 1; i < n - 1; i++) {
                        unew[i * n * n + j * n + k] = 0.125 * (
                            u[(i-1) * n * n + j * n + k] + u[(i+1) * n * n + j * n + k] + 
                            u[i * n * n + (j-1) * n + k] + u[i * n * n + (j+1) * n + k] + 
                            u[i * n * n + j * n + (k-1)] + u[i * n * n + j * n + (k+1)] + 
                            u[i * n * n + j * n + k]
                        );
                    }
                }
            }
            #pragma omp barrier
            #pragma omp for schedule(static)
            for (i = 0; i < n * n * n; i++) {
                u[i] = unew[i];
            }
        }
    }
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[(i * n * n) + (j * n) + k] = 0.125 * (
            u[((i-1) * n * n) + (j * n) + k] + u[((i+1) * n * n) + (j * n) + k] +
            u[(i * n * n) + ((j-1) * n) + k] + u[(i * n * n) + ((j+1) * n) + k] +
            u[(i * n * n) + (j * n) + (k-1)] + u[(i * n * n) + (j * n) + (k+1)] +
            u[(i * n * n) + (j * n) + k]
        );
    }
}

Code Block 2:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
    int i, j, k, iter;

    #pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
    {
        for (iter = 1; iter <= niter; ++iter) {
            #pragma omp for schedule(static)
            for (k = 1; k < n - 1; ++k) {
                for (j = 1; j < n - 1; ++j) {
                    for (i = 1; i < n - 1; ++i) {
                        unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] + u[i][j-1][k] +
                                                 u[i][j+1][k] + u[i][j][k-1] + u[i][j][k+1] + u[i][j][k]);
                    }
                }
            }
            #pragma omp barrier

            #pragma omp for schedule(static)
            for (k = 0; k < n; ++k) {
                for (j = 0; j < n; ++j) {
                    for (i = 0; i < n; ++i) {
                        u[i][j][k] = unew[i][j][k];
                    }
                }
            }
        }
    }
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        int idx = i + n * (j + n * k);
        unew[idx] = 0.125 * (u[idx - 1] + u[idx + 1] + u[idx - n] +
                           u[idx + n] + u[idx - n*n] + u[idx + n*n] + u[idx]);
    }
}

Code Block 3:
void jacobi_parallel(double* u, double* unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    cudaMalloc(&d_u, size);
    cudaMalloc(&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);  // Set appropriate block size
    dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x, 
                   (n + threadsPerBlock.y - 1) / threadsPerBlock.y, 
                   (n + threadsPerBlock.z - 1) / threadsPerBlock.z);

    for (int iter = 0; iter < niter; iter++) {
        jacobi_kernel<<<numBlocks, threadsPerBlock>>>(d_u, d_unew, n);
        cudaMemcpy(d_u, d_unew, size, cudaMemcpyDeviceToDevice);
    }

    cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;  // Skip the border
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        unew[i + n * (j + n * k)] = 0.125 * (
            u[(i-1) + n * (j + n * k)] + 
            u[(i+1) + n * (j + n * k)] + 
            u[i + n * ((j-1) + n * k)] + 
            u[i + n * ((j+1) + n * k)] + 
            u[i + n * (j + n * (k-1))] + 
            u[i + n * (j + n * (k+1))] + 
            u[i + n * (j + n * k)]
        );
    }
}

Code Block 4:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads) {
    int i, j, k, iter;

    #pragma omp parallel for collapse(3) num_threads(nthreads) private(i, j, k, iter)
    for (iter = 0; iter < niter; iter++) {
        #pragma omp parallel for schedule(static)
        for (k = 1; k < n - 1; k++) {
            for (j = 1; j < n - 1; j++) {
                for (i = 1; i < n - 1; i++) {
                    unew[i][j][k] = 0.125 * (u[i-1][j][k] + u[i+1][j][k] +
                                             u[i][j-1][k] + u[i][j+1][k] +
                                             u[i][j][k-1] + u[i][j][k+1] +
                                             u[i][j][k]);
                }
            }
        }
        #pragma omp barrier
        #pragma omp parallel for collapse(3)
        for (k = 0; k < n; k++) {
            for (j = 0; j < n; j++) {
                for (i = 0; i < n; i++) {
                    u[i][j][k] = unew[i][j][k];
                }
            }
        }
        #pragma omp barrier
    }
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    if (i >= 1 && i < n - 1 && j >= 1 && j < n - 1 && k >= 1 && k < n - 1) {
        int idx = i + j * n + k * n * n;
        unew[idx] = 0.125 * (u[(i-1) + j * n + k * n * n] + u[(i+1) + j * n + k * n * n] +
                             u[i + (j-1) * n + k * n * n] + u[i + (j+1) * n + k * n * n] +
                             u[i + j * n + (k-1) * n * n] + u[i + j * n + (k+1) * n * n] +
                             u[i + j * n + k * n * n]);
    }
}

Code Block 5:
void jacobi_parallel(double* u, double* unew, int n, int niter, int nthreads) {
    int i, j, k, iter;
    #pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
    {
        for (iter = 1; iter <= niter; iter++) {
            #pragma omp for schedule(static)
            for (k = 1; k < n - 1; k++) {
                for (j = 1; j < n - 1; j++) {
                    for (i = 1; i < n - 1; i++) {
                        unew[i + n * (j + n * k)] = 0.125 * (u[(i-1) + n * (j + n * k)] +
                                                             u[(i+1) + n * (j + n * k)] +
                                                             u[i + n * ((j-1) + n * k)] +
                                                             u[i + n * ((j+1) + n * k)] +
                                                             u[i + n * (j + n * (k-1))] +
                                                             u[i + n * (j + n * (k+1))] +
                                                             u[i + n * (j + n * k)]);
                    }
                }
            }
            #pragma omp barrier
            #pragma omp for schedule(static)
            for (k = 1; k < n - 1; k++) {
                for (j = 1; j < n - 1; j++) {
                    for (i = 1; i < n - 1; i++) {
                        u[i + n * (j + n * k)] = unew[i + n * (j + n * k)];
                    }
                }
            }
        }
    }
}

__global__ void jacobi_kernel(double* d_u, double* d_unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        d_unew[i + n * (j + n * k)] = 0.125 * (d_u[(i-1) + n * (j + n * k)] +
                                               d_u[(i+1) + n * (j + n * k)] +
                                               d_u[i + n * ((j-1) + n * k)] +
                                               d_u[i + n * ((j+1) + n * k)] +
                                               d_u[i + n * (j + n * (k-1))] +
                                               d_u[i + n * (j + n * (k+1))] +
                                               d_u[i + n * (j + n * k)]);
    }
}

Code Block 6:
elements
    if (i >= 1 && i < n-1 && j >= 1 && j < n-1 && k >= 1 && k < n-1) {
        int idx = i + n * (j + n * k);
        int idx_im1 = (i - 1) + n * (j + n * k);
        int idx_ip1 = (i + 1) + n * (j + n * k);
        int idx_jm1 = i + n * ((j - 1) + n * k);
        int idx_jp1 = i + n * ((j + 1) + n * k);
        int idx_km1 = i + n * (j + n * (k - 1));
        int idx_kp1 = i + n * (j + n * (k + 1));
        unew[idx] = 0.125 * (u[idx_im1] + u[idx_ip1] + u[idx_jm1] +
                             u[idx_jp1] + u[idx_km1] + u[idx_kp1] + u[idx]);
    }

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    int k = blockIdx.z * blockDim.z + threadIdx.z;

    // Ensure we don't operate on the boundary elements
    if (i >= 1 && i < n-1 && j >= 1 && j < n-1 && k >= 1 && k < n-1) {
        int idx = i + n * (j + n * k);
        int idx_im1 = (i - 1) + n * (j + n * k);
        int idx_ip1 = (i + 1) + n * (j + n * k);
        int idx_jm1 = i + n * ((j - 1) + n * k);
        int idx_jp1 = i + n * ((j + 1) + n * k);
        int idx_km1 = i + n * (j + n * (k - 1));
        int idx_kp1 = i + n * (j + n * (k + 1));
        unew[idx] = 0.125 * (u[idx_im1] + u[idx_ip1] + u[idx_jm1] +
                             u[idx_jp1] + u[idx_km1] + u[idx_kp1] + u[idx]);
    }
}

Code Block 7:
void jacobi_parallel(double ***u, double ***unew, int n, int niter, int nthreads)
{
    int i, j, k, iter;

    omp_set_num_threads(nthreads);

    #pragma omp parallel private(i, j, k, iter)
    {
        for (iter = 1; iter <= niter; iter++)
        {
            #pragma omp for schedule(static)
            for (k = 1; k < n - 1; k++)
            {
                for (j = 1; j < n - 1; j++)
                {
                    for (i = 1; i < n - 1; i++)
                    {
                        unew[k][j][i] = 0.125 * (u[k][j][i-1] + u[k][j][i+1] + 
                                                  u[k][j-1][i] + u[k][j+1][i] + 
                                                  u[k-1][j][i] + u[k+1][j][i] + 
                                                  u[k][j][i]);
                    }
                }
            }
            #pragma omp barrier

            #pragma omp for schedule(static)
            for (k = 0; k < n; k++)
            {
                for (j = 0; j < n; j++)
                {
                    for (i = 0; i < n; i++)
                    {
                        u[k][j][i] = unew[k][j][i];
                    }
                }
            }
        }
    }
}

__global__ void jacobi_kernel(double *u, double *unew, int n)
{
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1)
    {
        int idx = k * n * n + j * n + i;
        int idx_im = k * n * n + j * n + (i - 1);
        int idx_ip = k * n * n + j * n + (i + 1);
        int idx_jm = k * n * n + (j - 1) * n + i;
        int idx_jp = k * n * n + (j + 1) * n + i;
        int idx_km = (k - 1) * n * n + j * n + i;
        int idx_kp = (k + 1) * n * n + j * n + i;

        unew[idx] = 0.125 * (u[idx_im] + u[idx_ip] + u[idx_jm] + u[idx_jp] + u[idx_km] + u[idx_kp] + u[idx]);
    }
}

Code Block 8:
void jacobi_parallel(double *u, double *unew, int n, int niter, int nthreads) {
    int i, j, k, iter;
    #pragma omp parallel num_threads(nthreads) private(i, j, k, iter)
    {
        for (iter = 0; iter < niter; iter++) {
            #pragma omp for schedule(static)
            for (k = 1; k < n - 1; k++) {
                for (j = 1; j < n - 1; j++) {
                    for (i = 1; i < n - 1; i++) {
                        unew[(i * n + j) * n + k] = 0.125 * (
                            u[((i - 1) * n + j) * n + k] + u[((i + 1) * n + j) * n + k] +
                            u[(i * n + (j - 1)) * n + k] + u[(i * n + (j + 1)) * n + k] +
                            u[(i * n + j) * n + (k - 1)] + u[(i * n + j) * n + (k + 1)] +
                            u[(i * n + j) * n + k]
                        );
                    }
                }
            }
            #pragma omp barrier
            #pragma omp for schedule(static)
            for (k = 0; k < n; k++) {
                for (j = 0; j < n; j++) {
                    for (i = 0; i < n; i++) {
                        u[(i * n + j) * n + k] = unew[(i * n + j) * n + k];
                    }
                }
            }
        }
    }
}

__global__ void jacobi_kernel(double *u, double *unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n - 1 && j < n - 1 && k < n - 1) {
        unew[(i * n + j) * n + k] = 0.125 * (
            u[((i - 1) * n + j) * n + k] + u[((i + 1) * n + j) * n + k] +
            u[(i * n + (j - 1)) * n + k] + u[(i * n + (j + 1)) * n + k] +
            u[(i * n + j) * n + (k - 1)] + u[(i * n + j) * n + (k + 1)] +
            u[(i * n + j) * n + k]
        );
    }
}

Code Block 9:
void jacobi_parallel(double* u, double* unew, int n, int niter, int nthreads) {
    // Size of the grid and blocks for CUDA kernel
    dim3 block(nthreads, nthreads, nthreads);
    dim3 grid((n + nthreads - 2) / nthreads, (n + nthreads - 2) / nthreads, (n + nthreads - 2) / nthreads);

    // Allocate device memory
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);
    cudaMalloc((void**)&d_u, size);
    cudaMalloc((void**)&d_unew, size);

    // Copy data to device
    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_unew, unew, size, cudaMemcpyHostToDevice);

    for (int iter = 0; iter < niter; iter++) {
        // Launch the kernel
        jacobi_kernel<<<grid, block>>>(d_u, d_unew, n);
        
        // Synchronize threads
        cudaDeviceSynchronize();
        
        // Swap pointers for next iteration
        double* temp = d_u;
        d_u = d_unew;
        d_unew = temp;
    }

    // Copy data back to host
    cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);
    cudaMemcpy(unew, d_unew, size, cudaMemcpyHostToDevice); // Ensure `unew` holds the last iteration data

    // Free device memory
    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobi_kernel(double* u, double* unew, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int k = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[IDX(i, j, k, n)] = 0.125 * (
            u[IDX(i-1, j, k, n)] + u[IDX(i+1, j, k, n)] +
            u[IDX(i, j-1, k, n)] + u[IDX(i, j+1, k, n)] +
            u[IDX(i, j, k-1, n)] + u[IDX(i, j, k+1, n)] +
            u[IDX(i, j, k, n)]);
    }
}

Code Block 10:
void jacobi_parallel(double *u, double *unew, int n, int niter) {
    double *d_u, *d_unew;
    size_t size = n * n * n * sizeof(double);

    cudaMalloc((void**)&d_u, size);
    cudaMalloc((void**)&d_unew, size);

    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_unew, unew, size, cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(8, 8, 8);
    dim3 numBlocks((n-2)/8 + 1, (n-2)/8 + 1, (n-2)/8 + 1);

    for (int iter = 0; iter < niter; iter++) {
        jacobiKernel<<<numBlocks, threadsPerBlock>>>(d_u, d_unew, n);
        cudaMemcpy(d_u, d_unew, size, cudaMemcpyDeviceToDevice);
        cudaDeviceSynchronize();
    }

    cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);

    cudaFree(d_u);
    cudaFree(d_unew);
}

__global__ void jacobiKernel(double *u, double *unew, int n) {
    int k = blockIdx.x * blockDim.x + threadIdx.x + 1;
    int j = blockIdx.y * blockDim.y + threadIdx.y + 1;
    int i = blockIdx.z * blockDim.z + threadIdx.z + 1;

    if (i < n-1 && j < n-1 && k < n-1) {
        unew[i * n * n + j * n + k] = 0.125 * (u[(i-1) * n * n + j * n + k] + u[(i+1) * n * n + j * n + k]
                                             + u[i * n * n + (j-1) * n + k] + u[i * n * n + (j+1) * n + k]
                                             + u[i * n * n + j * n + (k-1)] + u[i * n * n + j * n + (k+1)]
                                             + u[i * n * n + j * n + k]);
    }
}

