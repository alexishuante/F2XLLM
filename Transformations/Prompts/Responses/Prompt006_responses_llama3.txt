Output 1:
Here is the equivalent C/C++ OpenMP code for the Fortran OpenACC code you provided:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  #pragma omp parallel for private(i, j, l, temp) collapse(2)
  for (j = 0; j < n; j++) {
    for (i = 0; i < m; i++) {
      temp = 0.0;
      for (l = 0; l < k; l++) {
        temp += a[i * lda + l] * b[l * ldb + j];
      }
      c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
  }
}
Note that in C/C++, arrays are represented as pointers, and the indexing is done manually using the lda, ldb, and ldc parameters. Also, the collapse(2) clause is used to collapse the two nested loops into a single parallel loop.


Output 2:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
#pragma omp parallel for private(i, j, l, temp) collapse(2)
  for (j = 0; j < n; j++) {
    for (i = 0; i < m; i++) {
      temp = 0.0;
      for (l = 0; l < k; l++) {
        temp += a[i * lda + l] * b[l * ldb + j];
      }
      c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
  }
}
Note that in C/C++, arrays are 0-indexed, so the loop indices start from 0 instead of 1. Also, the array accesses are done using the * operator instead of the () notation. Additionally, the private clause in the OpenMP directive is used to specify that the variables i, j, l, and temp are private to each thread.


Output 3:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i, j, l;
    double temp;
    #pragma omp parallel for private(i, j, l, temp) collapse(2)
    for (j = 0; j < n; j++) {
        for (i = 0; i < m; i++) {
            temp = 0.0;
            for (l = 0; l < k; l++) {
                temp += a[i * lda + l] * b[l * ldb + j];
            }
            c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
        }
    }
}
Note that in C/C++, arrays are 0-indexed, whereas in Fortran, they are 1-indexed. Also, the lda, ldb, and ldc parameters are used to access the elements of the matrices a, b, and c respectively, since C/C++ uses row-major ordering, unlike Fortran's column-major ordering.


Output 4:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i, j, l;
    double temp;
    #pragma omp parallel for private(i, j, l, temp) collapse(2)
    for (j = 0; j < n; j++) {
        for (i = 0; i < m; i++) {
            temp = 0.0;
            for (l = 0; l < k; l++) {
                temp += a[i * lda + l] * b[l * ldb + j];
            }
            c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
        }
    }
}
Note that in C/C++, arrays are 0-indexed, whereas in Fortran, they are 1-indexed by default. Also, the lda, ldb, and ldc parameters are used to access the elements of the arrays a, b, and c respectively, since C/C++ does not have built-in support for 2D arrays.


Output 5:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  #pragma omp parallel for collapse(2) private(i, j, l, temp)
  for (j = 0; j < n; j++) {
    for (i = 0; i < m; i++) {
      temp = 0.0;
      for (l = 0; l < k; l++) {
        temp += a[i * lda + l] * b[l * ldb + j];
      }
      c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
  }
}
Note that in C/C++, arrays are 0-indexed, so the loop indices start from 0 instead of 1. Also, the array indices are calculated manually using the lda, ldb, and ldc parameters, since C/C++ does not have built-in support for 2D arrays with arbitrary leading dimensions like Fortran does.
I hope this helps! Let me know if you have any questions.


Output 6:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  #pragma omp parallel for private(i, j, l, temp) collapse(2)
  for (j = 0; j < n; j++) {
    for (i = 0; i < m; i++) {
      temp = 0.0;
      for (l = 0; l < k; l++) {
        temp += a[i * lda + l] * b[l * ldb + j];
      }
      c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
  }
}
Note that in C/C++, arrays are 0-indexed, so the loop indices start from 0 instead of 1. Also, the array indices are calculated manually using the lda, ldb, and ldc parameters, since C/C++ does not have built-in support for 2D arrays with arbitrary leading dimensions like Fortran does.


Output 7:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  #pragma omp parallel for private(i, j, l, temp) collapse(2)
  for (j = 0; j < n; j++) {
    for (i = 0; i < m; i++) {
      temp = 0.0;
      for (l = 0; l < k; l++) {
        temp += a[i * lda + l] * b[l * ldb + j];
      }
      c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
  }
}
Note that in C/C++, arrays are 0-indexed, so the loop indices start from 0 instead of 1. Also, the array indices are calculated manually using the lda, ldb, and ldc parameters, since C/C++ does not have built-in support for 2D arrays with arbitrary leading dimensions like Fortran does.


Output 8:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i, j, l;
    double temp;
    #pragma omp parallel for collapse(2) private(i, j, l, temp)
    for (j = 0; j < n; j++) {
        for (i = 0; i < m; i++) {
            temp = 0.0;
            for (l = 0; l < k; l++) {
                temp += a[i * lda + l] * b[l * ldb + j];
            }
            c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
        }
    }
}
Note that in C/C++, arrays are 0-indexed, whereas in Fortran, they are 1-indexed by default. Also, the collapse(2) clause in the OpenMP directive is used to collapse the two nested loops into a single loop, which can improve parallelization efficiency. The private clause is used to ensure that each thread has its own private copies of the variables i, j, l, and temp.


Output 9:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
    int i, j, l;
    double temp;
    #pragma omp parallel for private(i, j, l, temp) collapse(2)
    for (j = 0; j < n; j++) {
        for (i = 0; i < m; i++) {
            temp = 0.0;
            for (l = 0; l < k; l++) {
                temp += a[i * lda + l] * b[l * ldb + j];
            }
            c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
        }
    }
}
Note that in C/C++, arrays are passed to functions as pointers, and the row-major ordering is used by default. Therefore, the indexing in the nested loops is adjusted accordingly. Also, the collapse(2) clause is used to collapse the two outer loops into a single parallel loop, similar to the Fortran OpenACC code.


Output 10:
Here is the equivalent C/C++ OpenMP code for the given Fortran OpenACC code:
void gemm_parallel(int m, int n, int k, double alpha, double *a, int lda, double *b, int ldb, double beta, double *c, int ldc) {
  int i, j, l;
  double temp;
  #pragma omp parallel for private(i, j, l, temp) collapse(2)
  for (j = 0; j < n; j++) {
    for (i = 0; i < m; i++) {
      temp = 0.0;
      for (l = 0; l < k; l++) {
        temp += a[i * lda + l] * b[l * ldb + j];
      }
      c[i * ldc + j] = alpha * temp + beta * c[i * ldc + j];
    }
  }
}
Note that I've assumed real(kind=8) in Fortran corresponds to double in C/C++. Also, I've used lda and ldb to access elements in arrays a and b respectively, as Fortran stores arrays in column-major order.


